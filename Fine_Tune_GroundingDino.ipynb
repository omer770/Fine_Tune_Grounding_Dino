{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJrwclVQM1nF",
        "outputId": "1e5e51e9-760a-4c41-c779-089efbd796a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = None #'<add_you_coco_dataset_dive_link>'  #Eg. '1fdgdgssytsyusrtyshgg' ensure data to be zip\n",
        "file_id_weigths = None #'<trained_weights any>' #Eg. '1fdgdgsgsjusysetg' : format: model_weights_00_100.pth"
      ],
      "metadata": {
        "id": "N2SJSQfgjyel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import shutil\n",
        "Gdrive = False # IF you want to save data of images keep true\n",
        "folder_path = '/content/drive/MyDrive/' if Gdrive else '/content/'"
      ],
      "metadata": {
        "id": "lJ-ibqGzj9d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd {folder_path} #goto drive location\n",
        "git clone https://github.com/omer770/Fine_Tune_Grounding_Dino.git\n",
        "cd Fine_Tune_Grounding_Dino\n",
        "cd weights\n",
        "wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth #default weights\n",
        "cd /content/"
      ],
      "metadata": {
        "id": "qeMMJ4zClp-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d5c6d0-9eaf-408f-805d-a844621df55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 1: cd: {folder_path}: No such file or directory\n",
            "Cloning into 'Fine_Tune_Grounding_Dino'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if file_id:\n",
        "  zip_path = gdown.download(id=file_id)\n",
        "  !unzip -q {zip_path} -d {folder_path+'Fine_Tune_Grounding_Dino/data'}\n",
        "if file_id_weigths:\n",
        "  weights_path = gdown.download(id=file_id_weigths)\n",
        "  weights_Dir = Path('/content/drive/MyDrive/Colab_zip/GroundingDINO/weights')\n",
        "  weights_Dir.mkdir(parents=True, exist_ok=True)\n",
        "  shutil.move(weights_path, weights_Dir)"
      ],
      "metadata": {
        "id": "w_-c9cRjjk4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "j6wIfMM4THQ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "584d7ed7-4355-45c5-e4f0-8619f5b4dfe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run at Fine_Tune_Grounding_Dino directory"
      ],
      "metadata": {
        "id": "w9rDz3vHop3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {folder_path+'Fine_Tune_Grounding_Dino'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66Ho6XsBVe9c",
        "outputId": "cb3429fa-4121-4840-8662-ec5ad7f62eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Fine_Tune_Grounding_Dino\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "id": "PsbasW6epVvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8f2ad4c-ec1b-40c7-eb94-1049cb2b45c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/254.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m245.8/254.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "id": "_T3FSPmB-G0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groundingdino.util.dataset import annotation_coco_2_pd_converter\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2"
      ],
      "metadata": {
        "id": "SZMvwpXIok_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_2_images = folder_path+'/Fine_Tune_Grounding_Dino/data/images'\n",
        "path_2_csv = folder_path+'Fine_Tune_Grounding_Dino/data/annotations/annotation.csv'\n",
        "path_2_ann_json = folder_path+'Fine_Tune_Grounding_Dino/data/annotations/instances_default.json'\n",
        "path_2_sub_csv = path_2_csv.replace('annotation.','annotation_sub.')\n",
        "df_ann, df_all, df_shape = annotation_coco_2_pd_converter(path_2_ann_json = path_2_ann_json,path_2_images = path_2_images,\n",
        "                                                  path_2_sub_csv=path_2_sub_csv,path_2_csv = path_2_csv)\n"
      ],
      "metadata": {
        "id": "7Cg7mk0EomBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all"
      ],
      "metadata": {
        "id": "xMSNrC1X_Ntb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "5bdcaa78-cf07-4f30-c719-cb38a5ff9e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               label_name  bbox_x  bbox_y  bbox_width  bbox_height  \\\n",
              "13820  circular structure     530     263          25           25   \n",
              "4160   circular structure     631       0         163           83   \n",
              "14987  circular structure      79     289          29           28   \n",
              "21849             caravan     421     598          71           27   \n",
              "18449            building       0     632          88          155   \n",
              "14269             caravan     373     612          27           74   \n",
              "539              building      86       0         119           60   \n",
              "8931                 pool     446     435          42           44   \n",
              "15379  circular structure      36     208          11           12   \n",
              "6252              caravan     140     145          25           64   \n",
              "\n",
              "                image_name  image_width  image_height  \n",
              "13820  61547_108196_18.jpg         1024          1024  \n",
              "4160   61592_108145_18.jpg         1024          1024  \n",
              "14987  61543_108069_18.jpg         1024          1024  \n",
              "21849  61527_108064_18.jpg         1024          1024  \n",
              "18449  61565_108191_18.jpg         1024          1024  \n",
              "14269  61545_108216_18.jpg         1024          1024  \n",
              "539    61609_108220_18.jpg         1024          1024  \n",
              "8931   61561_108131_18.jpg         1024          1024  \n",
              "15379  61540_108241_18.jpg         1024          1024  \n",
              "6252   61580_108243_18.jpg         1024          1024  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a875cec9-039d-49da-9c47-53861b3905a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label_name</th>\n",
              "      <th>bbox_x</th>\n",
              "      <th>bbox_y</th>\n",
              "      <th>bbox_width</th>\n",
              "      <th>bbox_height</th>\n",
              "      <th>image_name</th>\n",
              "      <th>image_width</th>\n",
              "      <th>image_height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13820</th>\n",
              "      <td>circular structure</td>\n",
              "      <td>530</td>\n",
              "      <td>263</td>\n",
              "      <td>25</td>\n",
              "      <td>25</td>\n",
              "      <td>61547_108196_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4160</th>\n",
              "      <td>circular structure</td>\n",
              "      <td>631</td>\n",
              "      <td>0</td>\n",
              "      <td>163</td>\n",
              "      <td>83</td>\n",
              "      <td>61592_108145_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14987</th>\n",
              "      <td>circular structure</td>\n",
              "      <td>79</td>\n",
              "      <td>289</td>\n",
              "      <td>29</td>\n",
              "      <td>28</td>\n",
              "      <td>61543_108069_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21849</th>\n",
              "      <td>caravan</td>\n",
              "      <td>421</td>\n",
              "      <td>598</td>\n",
              "      <td>71</td>\n",
              "      <td>27</td>\n",
              "      <td>61527_108064_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18449</th>\n",
              "      <td>building</td>\n",
              "      <td>0</td>\n",
              "      <td>632</td>\n",
              "      <td>88</td>\n",
              "      <td>155</td>\n",
              "      <td>61565_108191_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14269</th>\n",
              "      <td>caravan</td>\n",
              "      <td>373</td>\n",
              "      <td>612</td>\n",
              "      <td>27</td>\n",
              "      <td>74</td>\n",
              "      <td>61545_108216_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>building</td>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>119</td>\n",
              "      <td>60</td>\n",
              "      <td>61609_108220_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8931</th>\n",
              "      <td>pool</td>\n",
              "      <td>446</td>\n",
              "      <td>435</td>\n",
              "      <td>42</td>\n",
              "      <td>44</td>\n",
              "      <td>61561_108131_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15379</th>\n",
              "      <td>circular structure</td>\n",
              "      <td>36</td>\n",
              "      <td>208</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>61540_108241_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6252</th>\n",
              "      <td>caravan</td>\n",
              "      <td>140</td>\n",
              "      <td>145</td>\n",
              "      <td>25</td>\n",
              "      <td>64</td>\n",
              "      <td>61580_108243_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a875cec9-039d-49da-9c47-53861b3905a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a875cec9-039d-49da-9c47-53861b3905a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a875cec9-039d-49da-9c47-53861b3905a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-169b7a4c-3c00-43a6-8b73-12d4e0169313\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-169b7a4c-3c00-43a6-8b73-12d4e0169313')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-169b7a4c-3c00-43a6-8b73-12d4e0169313 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_17dddf10-2d64-4184-ab61-8625bb92945a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_all')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_17dddf10-2d64-4184-ab61-8625bb92945a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_all');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_all",
              "summary": "{\n  \"name\": \"df_all\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"label_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"caravan\",\n          \"pool\",\n          \"circular structure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bbox_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 230,\n        \"min\": 0,\n        \"max\": 631,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          36,\n          631,\n          373\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bbox_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 241,\n        \"min\": 0,\n        \"max\": 632,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          208,\n          0,\n          612\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bbox_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49,\n        \"min\": 11,\n        \"max\": 163,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          42,\n          163,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bbox_height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41,\n        \"min\": 12,\n        \"max\": 155,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          12,\n          83,\n          74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"61540_108241_18.jpg\",\n          \"61592_108145_18.jpg\",\n          \"61545_108216_18.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1024,\n        \"max\": 1024,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1024,\n        \"max\": 1024,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ann"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "EP6VDHtxo2nQ",
        "outputId": "79c3a27b-ea5c-4f60-9044-4a279d608692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label_name  bbox_x  bbox_y  bbox_width  bbox_height           image_name  \\\n",
              "0   building     392     788         173          121  61614_108109_18.jpg   \n",
              "1   building     673     259         148          133  61614_108109_18.jpg   \n",
              "2   building     981    1007          39           16  61614_108109_18.jpg   \n",
              "3   building     494     519         116          123  61614_108109_18.jpg   \n",
              "4   building     866     136         157          111  61614_108109_18.jpg   \n",
              "5   building     760       0          32           15  61614_108109_18.jpg   \n",
              "6   building     591     832          26           27  61614_108109_18.jpg   \n",
              "7   building     916     205         107          139  61614_108109_18.jpg   \n",
              "8   building       0     831         146          130  61614_108109_18.jpg   \n",
              "9   building      29     909         161          114  61614_108109_18.jpg   \n",
              "\n",
              "   image_width  image_height  \n",
              "0         1024          1024  \n",
              "1         1024          1024  \n",
              "2         1024          1024  \n",
              "3         1024          1024  \n",
              "4         1024          1024  \n",
              "5         1024          1024  \n",
              "6         1024          1024  \n",
              "7         1024          1024  \n",
              "8         1024          1024  \n",
              "9         1024          1024  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebb9e982-fae8-4cee-b72a-765d365cccab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label_name</th>\n",
              "      <th>bbox_x</th>\n",
              "      <th>bbox_y</th>\n",
              "      <th>bbox_width</th>\n",
              "      <th>bbox_height</th>\n",
              "      <th>image_name</th>\n",
              "      <th>image_width</th>\n",
              "      <th>image_height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>building</td>\n",
              "      <td>392</td>\n",
              "      <td>788</td>\n",
              "      <td>173</td>\n",
              "      <td>121</td>\n",
              "      <td>61614_108109_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>building</td>\n",
              "      <td>673</td>\n",
              "      <td>259</td>\n",
              "      <td>148</td>\n",
              "      <td>133</td>\n",
              "      <td>61614_108109_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>building</td>\n",
              "      <td>981</td>\n",
              "      <td>1007</td>\n",
              "      <td>39</td>\n",
              "      <td>16</td>\n",
              "      <td>61614_108109_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>building</td>\n",
              "      <td>494</td>\n",
              "      <td>519</td>\n",
              "      <td>116</td>\n",
              "      <td>123</td>\n",
              "      <td>61614_108109_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>building</td>\n",
              "      <td>866</td>\n",
              "      <td>136</td>\n",
              "      <td>157</td>\n",
              "      <td>111</td>\n",
              "      <td>61614_108109_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>building</td>\n",
              "      <td>760</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>15</td>\n",
              "      <td>61614_108109_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>building</td>\n",
              "      <td>591</td>\n",
              "      <td>832</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>61614_108109_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>building</td>\n",
              "      <td>916</td>\n",
              "      <td>205</td>\n",
              "      <td>107</td>\n",
              "      <td>139</td>\n",
              "      <td>61614_108109_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>building</td>\n",
              "      <td>0</td>\n",
              "      <td>831</td>\n",
              "      <td>146</td>\n",
              "      <td>130</td>\n",
              "      <td>61614_108109_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>building</td>\n",
              "      <td>29</td>\n",
              "      <td>909</td>\n",
              "      <td>161</td>\n",
              "      <td>114</td>\n",
              "      <td>61614_108109_18.jpg</td>\n",
              "      <td>1024</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebb9e982-fae8-4cee-b72a-765d365cccab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ebb9e982-fae8-4cee-b72a-765d365cccab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ebb9e982-fae8-4cee-b72a-765d365cccab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0cf53045-87d7-4b2a-a721-cfc1750a423c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0cf53045-87d7-4b2a-a721-cfc1750a423c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0cf53045-87d7-4b2a-a721-cfc1750a423c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fd3cddff-1d0a-4795-8059-d1c6c7a340de\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_ann')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fd3cddff-1d0a-4795-8059-d1c6c7a340de button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_ann');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_ann",
              "summary": "{\n  \"name\": \"df_ann\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"label_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"building\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bbox_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 346,\n        \"min\": 0,\n        \"max\": 981,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bbox_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 369,\n        \"min\": 0,\n        \"max\": 1007,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          831\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bbox_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57,\n        \"min\": 26,\n        \"max\": 173,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          146\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bbox_height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 15,\n        \"max\": 139,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          130\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"61614_108109_18.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1024,\n        \"max\": 1024,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1024,\n        \"max\": 1024,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "VIAoAKnEql0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "865f05bb-a05c-4c04-a5f3-54cb0699c139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 17 11:24:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_run.py"
      ],
      "metadata": {
        "id": "juuaoF43oqoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e3d524e-3b6f-4519-b949-3114e807f3a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
            "final text_encoder_type: bert-base-uncased\n",
            "choosen weights:  /content/drive/MyDrive/Colab_zip/GroundingDINO/weights/model_weights_02_020.pth\n",
            "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "Regression and Classification loss are 0.49459874629974365 and 0.010162215679883957\n",
            "Processed image 1/138, Loss: 0.015108203515410423\n",
            "Regression and Classification loss are 0.18854466080665588 and 0.0016025402583181858\n",
            "Processed image 2/138, Loss: 0.0034879869781434536\n",
            "Regression and Classification loss are 0.19442079961299896 and 0.009044761769473553\n",
            "Processed image 3/138, Loss: 0.01098896935582161\n",
            "Regression and Classification loss are 1.1090642213821411 and 0.00107981835026294\n",
            "Processed image 4/138, Loss: 0.01217046007514\n",
            "Regression and Classification loss are 0.48330092430114746 and 0.002659597434103489\n",
            "Processed image 5/138, Loss: 0.007492606528103352\n",
            "Regression and Classification loss are 2.070056676864624 and 0.005688520148396492\n",
            "Processed image 6/138, Loss: 0.02638908661901951\n",
            "Regression and Classification loss are 0.657515823841095 and 0.00382114271633327\n",
            "Processed image 7/138, Loss: 0.010396300815045834\n",
            "Regression and Classification loss are 0.24632754921913147 and 0.007344749756157398\n",
            "Processed image 8/138, Loss: 0.009808025322854519\n",
            "Regression and Classification loss are 30.266571044921875 and 0.010218211449682713\n",
            "Processed image 9/138, Loss: 0.3128839135169983\n",
            "Regression and Classification loss are 0.6102139949798584 and 0.004625914618372917\n",
            "Processed image 10/138, Loss: 0.010728053748607635\n",
            "Regression and Classification loss are 0.32836636900901794 and 0.006691934075206518\n",
            "Processed image 11/138, Loss: 0.009975597262382507\n",
            "Regression and Classification loss are 6.220704555511475 and 0.002897446509450674\n",
            "Processed image 12/138, Loss: 0.06510449200868607\n",
            "Regression and Classification loss are 1.089395523071289 and 0.0017194068059325218\n",
            "Processed image 13/138, Loss: 0.012613361701369286\n",
            "Regression and Classification loss are 1.534794807434082 and 0.005387203302234411\n",
            "Processed image 14/138, Loss: 0.020735150203108788\n",
            "Regression and Classification loss are 0.7992668151855469 and 0.0011125041637569666\n",
            "Processed image 15/138, Loss: 0.009105172008275986\n",
            "Regression and Classification loss are 0.8747172355651855 and 0.004713844507932663\n",
            "Processed image 16/138, Loss: 0.013461017049849033\n",
            "Regression and Classification loss are 0.17123505473136902 and 0.0007049925625324249\n",
            "Processed image 17/138, Loss: 0.0024173432029783726\n",
            "Regression and Classification loss are 0.7944310307502747 and 0.0038791820406913757\n",
            "Processed image 18/138, Loss: 0.011823492124676704\n",
            "Regression and Classification loss are 4.543628215789795 and 0.0014876845525577664\n",
            "Processed image 19/138, Loss: 0.04692396521568298\n",
            "Regression and Classification loss are 2.314847946166992 and 0.0009190443670377135\n",
            "Processed image 20/138, Loss: 0.024067522957921028\n",
            "Regression and Classification loss are 1.4956592321395874 and 0.003171714022755623\n",
            "Processed image 21/138, Loss: 0.018128305673599243\n",
            "Regression and Classification loss are 0.7500007152557373 and 0.004864912014454603\n",
            "Processed image 22/138, Loss: 0.012364918366074562\n",
            "Regression and Classification loss are 1.3190114498138428 and 0.006280300673097372\n",
            "Processed image 23/138, Loss: 0.019470414146780968\n",
            "Regression and Classification loss are 0.8796766996383667 and 0.004218699410557747\n",
            "Processed image 24/138, Loss: 0.013015465810894966\n",
            "Regression and Classification loss are 16.22136878967285 and 0.004024263471364975\n",
            "Processed image 25/138, Loss: 0.1662379503250122\n",
            "Regression and Classification loss are 3.6390016078948975 and 0.0037320763804018497\n",
            "Processed image 26/138, Loss: 0.04012209177017212\n",
            "Regression and Classification loss are 1.4199551343917847 and 0.003282686695456505\n",
            "Processed image 27/138, Loss: 0.01748223789036274\n",
            "Regression and Classification loss are 1.7002078294754028 and 0.003740129992365837\n",
            "Processed image 28/138, Loss: 0.020742207765579224\n",
            "Regression and Classification loss are 0.4876413941383362 and 0.0027297453489154577\n",
            "Processed image 29/138, Loss: 0.007606158964335918\n",
            "Regression and Classification loss are 0.5575838088989258 and 0.0026139679830521345\n",
            "Processed image 30/138, Loss: 0.008189805783331394\n",
            "Regression and Classification loss are 0.5724235773086548 and 0.0033742524683475494\n",
            "Processed image 31/138, Loss: 0.00909848790615797\n",
            "Regression and Classification loss are 1.6363816261291504 and 0.0020206901244819164\n",
            "Processed image 32/138, Loss: 0.018384506925940514\n",
            "Regression and Classification loss are 3.247504234313965 and 0.004592524375766516\n",
            "Processed image 33/138, Loss: 0.03706756606698036\n",
            "Regression and Classification loss are 1.2657642364501953 and 0.003265861188992858\n",
            "Processed image 34/138, Loss: 0.015923503786325455\n",
            "Regression and Classification loss are 1.274704933166504 and 0.007583610713481903\n",
            "Processed image 35/138, Loss: 0.020330660045146942\n",
            "Regression and Classification loss are 0.8138319253921509 and 0.0036083830054849386\n",
            "Processed image 36/138, Loss: 0.011746702715754509\n",
            "Regression and Classification loss are 0.8911856412887573 and 0.005093097686767578\n",
            "Processed image 37/138, Loss: 0.014004954136908054\n",
            "Regression and Classification loss are 1.822949767112732 and 0.001035994617268443\n",
            "Processed image 38/138, Loss: 0.019265491515398026\n",
            "Regression and Classification loss are 0.33466044068336487 and 0.008447757922112942\n",
            "Processed image 39/138, Loss: 0.011794362217187881\n",
            "Regression and Classification loss are 1.433869481086731 and 0.0077508799731731415\n",
            "Processed image 40/138, Loss: 0.022089574486017227\n",
            "Regression and Classification loss are 1.385206937789917 and 0.0014802804216742516\n",
            "Processed image 41/138, Loss: 0.015332349576056004\n",
            "Regression and Classification loss are 2.413302421569824 and 0.007359662558883429\n",
            "Processed image 42/138, Loss: 0.0314926840364933\n",
            "Regression and Classification loss are 0.520502507686615 and 0.0020152830984443426\n",
            "Processed image 43/138, Loss: 0.007220308296382427\n",
            "Regression and Classification loss are 0.53760826587677 and 0.0009335701470263302\n",
            "Processed image 44/138, Loss: 0.006309652701020241\n",
            "Regression and Classification loss are 13.15035629272461 and 0.001735273632220924\n",
            "Processed image 45/138, Loss: 0.13323883712291718\n",
            "Regression and Classification loss are 1.6579432487487793 and 0.005968695972114801\n",
            "Processed image 46/138, Loss: 0.0225481279194355\n",
            "Regression and Classification loss are 0.1369926929473877 and 0.0036755772307515144\n",
            "Processed image 47/138, Loss: 0.005045504309237003\n",
            "Regression and Classification loss are 0.5648500919342041 and 0.002955542877316475\n",
            "Processed image 48/138, Loss: 0.00860404409468174\n",
            "Regression and Classification loss are 1.6957359313964844 and 0.006871802266687155\n",
            "Processed image 49/138, Loss: 0.023829162120819092\n",
            "Regression and Classification loss are 4.7812819480896 and 0.004127813037484884\n",
            "Processed image 50/138, Loss: 0.05194063112139702\n",
            "Regression and Classification loss are 1.4611492156982422 and 0.0026896751951426268\n",
            "Processed image 51/138, Loss: 0.0173011664301157\n",
            "Regression and Classification loss are 2.456486940383911 and 0.006852810736745596\n",
            "Processed image 52/138, Loss: 0.03141767904162407\n",
            "Regression and Classification loss are 0.8820919990539551 and 0.0065245660953223705\n",
            "Processed image 53/138, Loss: 0.015345485880970955\n",
            "Regression and Classification loss are 0.5805089473724365 and 0.0031485222280025482\n",
            "Processed image 54/138, Loss: 0.008953611366450787\n",
            "Regression and Classification loss are 0.6005429029464722 and 0.0007036341703496873\n",
            "Processed image 55/138, Loss: 0.006709062959998846\n",
            "Regression and Classification loss are 1.431980848312378 and 0.003954735118895769\n",
            "Processed image 56/138, Loss: 0.018274543806910515\n",
            "Regression and Classification loss are 15.880309104919434 and 0.00437912018969655\n",
            "Processed image 57/138, Loss: 0.16318221390247345\n",
            "Regression and Classification loss are 1.0970624685287476 and 0.0038234987296164036\n",
            "Processed image 58/138, Loss: 0.01479412242770195\n",
            "Regression and Classification loss are 0.7818015813827515 and 0.00269674276933074\n",
            "Processed image 59/138, Loss: 0.0105147585272789\n",
            "Regression and Classification loss are 0.7481766939163208 and 0.009596364572644234\n",
            "Processed image 60/138, Loss: 0.017078131437301636\n",
            "Regression and Classification loss are 2.426872730255127 and 0.004162982106208801\n",
            "Processed image 61/138, Loss: 0.028431707993149757\n",
            "Regression and Classification loss are 1.1137207746505737 and 0.0013407738879323006\n",
            "Processed image 62/138, Loss: 0.012477980926632881\n",
            "Regression and Classification loss are 0.9805619120597839 and 0.0005038900417275727\n",
            "Processed image 63/138, Loss: 0.010309509001672268\n",
            "Regression and Classification loss are 0.32140737771987915 and 0.0020337512250989676\n",
            "Processed image 64/138, Loss: 0.00524782482534647\n",
            "Regression and Classification loss are 6.811348915100098 and 0.0031019258312880993\n",
            "Processed image 65/138, Loss: 0.07121541351079941\n",
            "Regression and Classification loss are 0.9013352394104004 and 0.004805245902389288\n",
            "Processed image 66/138, Loss: 0.013818597421050072\n",
            "Regression and Classification loss are 0.14755766093730927 and 0.0012114212149754167\n",
            "Processed image 67/138, Loss: 0.002686997875571251\n",
            "Regression and Classification loss are 0.8511233329772949 and 0.0055016567930579185\n",
            "Processed image 68/138, Loss: 0.014012889936566353\n",
            "Regression and Classification loss are 0.20315511524677277 and 0.002905971137806773\n",
            "Processed image 69/138, Loss: 0.004937522113323212\n",
            "Regression and Classification loss are 1.4209001064300537 and 0.0022818625438958406\n",
            "Processed image 70/138, Loss: 0.016490863636136055\n",
            "Regression and Classification loss are 0.7825183868408203 and 0.0011106751626357436\n",
            "Processed image 71/138, Loss: 0.008935858495533466\n",
            "Regression and Classification loss are 0.22005650401115417 and 0.004086334723979235\n",
            "Processed image 72/138, Loss: 0.00628689955919981\n",
            "Regression and Classification loss are 0.5430325269699097 and 0.00448470888659358\n",
            "Processed image 73/138, Loss: 0.009915033355355263\n",
            "Regression and Classification loss are 0.7795732021331787 and 0.0023369689006358385\n",
            "Processed image 74/138, Loss: 0.010132701136171818\n",
            "Regression and Classification loss are 0.7024961113929749 and 0.0020014781039208174\n",
            "Processed image 75/138, Loss: 0.009026438929140568\n",
            "Regression and Classification loss are 3.5664541721343994 and 0.002445738995447755\n",
            "Processed image 76/138, Loss: 0.03811027854681015\n",
            "Regression and Classification loss are 11.106134414672852 and 0.002710633911192417\n",
            "Processed image 77/138, Loss: 0.11377197504043579\n",
            "Regression and Classification loss are 0.20502296090126038 and 0.00393148697912693\n",
            "Processed image 78/138, Loss: 0.005981716327369213\n",
            "Regression and Classification loss are 0.8108997344970703 and 0.005183178931474686\n",
            "Processed image 79/138, Loss: 0.013292175717651844\n",
            "Regression and Classification loss are 2.699556350708008 and 0.002687402069568634\n",
            "Processed image 80/138, Loss: 0.029682964086532593\n",
            "Regression and Classification loss are 2.1761043071746826 and 0.00239321100525558\n",
            "Processed image 81/138, Loss: 0.02415425330400467\n",
            "Regression and Classification loss are 1.2290462255477905 and 0.0041770776733756065\n",
            "Processed image 82/138, Loss: 0.016467539593577385\n",
            "Regression and Classification loss are 0.8036090135574341 and 0.0036210743710398674\n",
            "Processed image 83/138, Loss: 0.011657164432108402\n",
            "Regression and Classification loss are 0.6780682802200317 and 0.007910586893558502\n",
            "Processed image 84/138, Loss: 0.014691269025206566\n",
            "Regression and Classification loss are 13.124112129211426 and 0.0057517727836966515\n",
            "Processed image 85/138, Loss: 0.13699288666248322\n",
            "Regression and Classification loss are 28.67865753173828 and 0.0034983407240360975\n",
            "Processed image 86/138, Loss: 0.2902849018573761\n",
            "Regression and Classification loss are 0.5685617327690125 and 0.0029146368615329266\n",
            "Processed image 87/138, Loss: 0.008600253611803055\n",
            "Regression and Classification loss are 1.958463191986084 and 0.008055933751165867\n",
            "Processed image 88/138, Loss: 0.02764056622982025\n",
            "Regression and Classification loss are 3.446776866912842 and 0.005692965351045132\n",
            "Processed image 89/138, Loss: 0.040160734206438065\n",
            "Regression and Classification loss are 0.27654486894607544 and 0.0033622807823121548\n",
            "Processed image 90/138, Loss: 0.006127729080617428\n",
            "Regression and Classification loss are 0.3049878180027008 and 0.0038558724336326122\n",
            "Processed image 91/138, Loss: 0.006905750371515751\n",
            "Regression and Classification loss are 1.4869556427001953 and 0.002906551817432046\n",
            "Processed image 92/138, Loss: 0.017776107415556908\n",
            "Regression and Classification loss are 1.5151944160461426 and 0.0050333659164607525\n",
            "Processed image 93/138, Loss: 0.020185310393571854\n",
            "Regression and Classification loss are 1.7903879880905151 and 0.003388714510947466\n",
            "Processed image 94/138, Loss: 0.021292593330144882\n",
            "Regression and Classification loss are 0.35936304926872253 and 0.002791204722598195\n",
            "Processed image 95/138, Loss: 0.006384835112839937\n",
            "Regression and Classification loss are 11.867535591125488 and 0.002371090231463313\n",
            "Processed image 96/138, Loss: 0.12104643881320953\n",
            "Regression and Classification loss are 1.357609748840332 and 0.004309685900807381\n",
            "Processed image 97/138, Loss: 0.017885781824588776\n",
            "Regression and Classification loss are 0.5742599368095398 and 0.0009251867304556072\n",
            "Processed image 98/138, Loss: 0.006667785812169313\n",
            "Regression and Classification loss are 6.441592693328857 and 0.0049439650028944016\n",
            "Processed image 99/138, Loss: 0.06935989111661911\n",
            "Regression and Classification loss are 0.7260069251060486 and 0.003929013852030039\n",
            "Processed image 100/138, Loss: 0.011189082637429237\n",
            "Regression and Classification loss are 1.410677194595337 and 0.0023233413230627775\n",
            "Processed image 101/138, Loss: 0.016430113464593887\n",
            "Regression and Classification loss are 7.111978054046631 and 0.004487998783588409\n",
            "Processed image 102/138, Loss: 0.0756077766418457\n",
            "Regression and Classification loss are 0.4799230694770813 and 0.001718408428132534\n",
            "Processed image 103/138, Loss: 0.006517638918012381\n",
            "Regression and Classification loss are 0.5489990711212158 and 0.004178797826170921\n",
            "Processed image 104/138, Loss: 0.009668787941336632\n",
            "Regression and Classification loss are 1.4479643106460571 and 0.002376122632995248\n",
            "Processed image 105/138, Loss: 0.016855765134096146\n",
            "Regression and Classification loss are 1.1218966245651245 and 0.00534887844696641\n",
            "Processed image 106/138, Loss: 0.01656784489750862\n",
            "Regression and Classification loss are 2.92419171333313 and 0.0039964537136256695\n",
            "Processed image 107/138, Loss: 0.03323836997151375\n",
            "Regression and Classification loss are 0.7898962497711182 and 0.0035900562070310116\n",
            "Processed image 108/138, Loss: 0.01148901879787445\n",
            "Regression and Classification loss are 2.2868902683258057 and 0.0017377256881445646\n",
            "Processed image 109/138, Loss: 0.024606626480817795\n",
            "Regression and Classification loss are 0.32767802476882935 and 0.0036296136677265167\n",
            "Processed image 110/138, Loss: 0.00690639391541481\n",
            "Regression and Classification loss are 0.3193291127681732 and 0.00456992955878377\n",
            "Processed image 111/138, Loss: 0.007763220928609371\n",
            "Regression and Classification loss are 7.091159343719482 and 0.0002902058477047831\n",
            "Processed image 112/138, Loss: 0.07120180130004883\n",
            "Regression and Classification loss are 0.7929220199584961 and 0.0016334798419848084\n",
            "Processed image 113/138, Loss: 0.009562700055539608\n",
            "Regression and Classification loss are 4.552512168884277 and 0.0009358798852190375\n",
            "Processed image 114/138, Loss: 0.04646100103855133\n",
            "Regression and Classification loss are 32.525177001953125 and 0.002351936185732484\n",
            "Processed image 115/138, Loss: 0.32760369777679443\n",
            "Regression and Classification loss are 0.8957598805427551 and 0.0014027247671037912\n",
            "Processed image 116/138, Loss: 0.010360322892665863\n",
            "Regression and Classification loss are 4.9901556968688965 and 0.007693394552916288\n",
            "Processed image 117/138, Loss: 0.05759495124220848\n",
            "Regression and Classification loss are 1.0256215333938599 and 0.0034379810094833374\n",
            "Processed image 118/138, Loss: 0.01369419600814581\n",
            "Regression and Classification loss are 1.2941417694091797 and 0.0013697349932044744\n",
            "Processed image 119/138, Loss: 0.014311152510344982\n",
            "Regression and Classification loss are 1.7248979806900024 and 0.005212239921092987\n",
            "Processed image 120/138, Loss: 0.022461218759417534\n",
            "Regression and Classification loss are 1.2125520706176758 and 0.0030312463641166687\n",
            "Processed image 121/138, Loss: 0.015156766399741173\n",
            "Regression and Classification loss are 0.6709624528884888 and 0.0028121331706643105\n",
            "Processed image 122/138, Loss: 0.009521758183836937\n",
            "Regression and Classification loss are 1.2442039251327515 and 0.004937601741403341\n",
            "Processed image 123/138, Loss: 0.01737964153289795\n",
            "Regression and Classification loss are 42.940330505371094 and 0.003928677644580603\n",
            "Processed image 124/138, Loss: 0.43333199620246887\n",
            "Regression and Classification loss are 4.697505474090576 and 0.004520757123827934\n",
            "Processed image 125/138, Loss: 0.051495812833309174\n",
            "Regression and Classification loss are 0.4280441999435425 and 0.001999232918024063\n",
            "Processed image 126/138, Loss: 0.0062796748243272305\n",
            "Regression and Classification loss are 4.043429851531982 and 0.006999557837843895\n",
            "Processed image 127/138, Loss: 0.04743385314941406\n",
            "Regression and Classification loss are 1.1586880683898926 and 0.005021811928600073\n",
            "Processed image 128/138, Loss: 0.016608692705631256\n",
            "Regression and Classification loss are 2.4001882076263428 and 0.0038289958611130714\n",
            "Processed image 129/138, Loss: 0.027830876410007477\n",
            "Regression and Classification loss are 0.6375929713249207 and 0.005148910451680422\n",
            "Processed image 130/138, Loss: 0.011524839326739311\n",
            "Regression and Classification loss are 1.5184741020202637 and 0.006712296511977911\n",
            "Processed image 131/138, Loss: 0.02189703658223152\n",
            "Regression and Classification loss are 0.8510403633117676 and 0.003948545549064875\n",
            "Processed image 132/138, Loss: 0.01245894841849804\n",
            "Regression and Classification loss are 1.4531619548797607 and 0.0035000487696379423\n",
            "Processed image 133/138, Loss: 0.018031667917966843\n",
            "Regression and Classification loss are 1.6859402656555176 and 0.0033375790808349848\n",
            "Processed image 134/138, Loss: 0.020196981728076935\n",
            "Regression and Classification loss are 0.7883909344673157 and 0.010889975354075432\n",
            "Processed image 135/138, Loss: 0.0187738835811615\n",
            "Regression and Classification loss are 0.3974840044975281 and 0.0007800447638146579\n",
            "Processed image 136/138, Loss: 0.004754884634166956\n",
            "Regression and Classification loss are 0.6299834847450256 and 0.0011345422826707363\n",
            "Processed image 137/138, Loss: 0.007434376981109381\n",
            "Regression and Classification loss are 1.1553292274475098 and 0.000734246801584959\n",
            "Processed image 138/138, Loss: 0.01228753849864006\n",
            "Epoch 1/50, Average Loss: 0.033329103010423154\n",
            "Model weights saved to /content/drive/MyDrive/Colab_zip/GroundingDINO/weights/model_weights_03_000.pth\n",
            "Regression and Classification loss are 1.297394037246704 and 0.012137604877352715\n",
            "Processed image 1/138, Loss: 0.025111544877290726\n",
            "Regression and Classification loss are 0.09748353064060211 and 0.0006402558647096157\n",
            "Processed image 2/138, Loss: 0.0016150912269949913\n",
            "Regression and Classification loss are 0.202364981174469 and 0.012311241589486599\n",
            "Processed image 3/138, Loss: 0.014334890991449356\n",
            "Regression and Classification loss are 0.7743903994560242 and 0.00535073596984148\n",
            "Processed image 4/138, Loss: 0.013094639405608177\n",
            "Regression and Classification loss are 0.09140940010547638 and 0.000899371865671128\n",
            "Processed image 5/138, Loss: 0.001813465845771134\n",
            "Regression and Classification loss are 1.5721367597579956 and 0.0037329222541302443\n",
            "Processed image 6/138, Loss: 0.019454289227724075\n",
            "Regression and Classification loss are 0.4402346909046173 and 0.0009867827175185084\n",
            "Processed image 7/138, Loss: 0.005389129742980003\n",
            "Regression and Classification loss are 0.3443540632724762 and 0.001387690776027739\n",
            "Processed image 8/138, Loss: 0.004831231199204922\n",
            "Regression and Classification loss are 28.783052444458008 and 0.004341426305472851\n",
            "Processed image 9/138, Loss: 0.2921719551086426\n",
            "Regression and Classification loss are 0.9216601848602295 and 0.0009772542398422956\n",
            "Processed image 10/138, Loss: 0.010193856433033943\n",
            "Regression and Classification loss are 0.2873570919036865 and 0.007404818665236235\n",
            "Processed image 11/138, Loss: 0.010278389789164066\n",
            "Regression and Classification loss are 7.764353275299072 and 0.006270953919738531\n",
            "Processed image 12/138, Loss: 0.08391448110342026\n",
            "Regression and Classification loss are 0.7987703084945679 and 0.0007509780116379261\n",
            "Processed image 13/138, Loss: 0.008738681674003601\n",
            "Regression and Classification loss are 1.3863964080810547 and 0.009496431797742844\n",
            "Processed image 14/138, Loss: 0.023360395804047585\n",
            "Regression and Classification loss are 0.6633418202400208 and 0.0006794020300731063\n",
            "Processed image 15/138, Loss: 0.007312820293009281\n",
            "Regression and Classification loss are 1.0200234651565552 and 0.005005883984267712\n",
            "Processed image 16/138, Loss: 0.015206118114292622\n",
            "Regression and Classification loss are 0.27475979924201965 and 0.0006262091337703168\n",
            "Processed image 17/138, Loss: 0.0033738070633262396\n",
            "Regression and Classification loss are 0.628855288028717 and 0.003674715291708708\n",
            "Processed image 18/138, Loss: 0.009963268414139748\n",
            "Regression and Classification loss are 4.245861053466797 and 0.0010443869978189468\n",
            "Processed image 19/138, Loss: 0.04350299388170242\n",
            "Regression and Classification loss are 2.322761058807373 and 0.003483002306893468\n",
            "Processed image 20/138, Loss: 0.026710612699389458\n",
            "Regression and Classification loss are 1.422210693359375 and 0.00576128950342536\n",
            "Processed image 21/138, Loss: 0.01998339593410492\n",
            "Regression and Classification loss are 0.4042932689189911 and 0.002824065275490284\n",
            "Processed image 22/138, Loss: 0.006866998039186001\n",
            "Regression and Classification loss are 1.0176767110824585 and 0.013572398573160172\n",
            "Processed image 23/138, Loss: 0.02374916523694992\n",
            "Regression and Classification loss are 0.8381330370903015 and 0.002793565858155489\n",
            "Processed image 24/138, Loss: 0.011174896731972694\n",
            "Regression and Classification loss are 16.700132369995117 and 0.0010024979710578918\n",
            "Processed image 25/138, Loss: 0.16800382733345032\n",
            "Regression and Classification loss are 4.105092525482178 and 0.004698076751083136\n",
            "Processed image 26/138, Loss: 0.0457490012049675\n",
            "Regression and Classification loss are 1.3692684173583984 and 0.002560195978730917\n",
            "Processed image 27/138, Loss: 0.016252879053354263\n",
            "Regression and Classification loss are 1.6570487022399902 and 0.001973103266209364\n",
            "Processed image 28/138, Loss: 0.018543589860200882\n",
            "Regression and Classification loss are 0.8624985218048096 and 0.0028732456266880035\n",
            "Processed image 29/138, Loss: 0.011498230509459972\n",
            "Regression and Classification loss are 7.512815475463867 and 0.0022132196463644505\n",
            "Processed image 30/138, Loss: 0.07734137028455734\n",
            "Regression and Classification loss are 1.081451654434204 and 0.0016586555866524577\n",
            "Processed image 31/138, Loss: 0.012473171576857567\n",
            "Regression and Classification loss are 1.7362725734710693 and 0.0018717001657932997\n",
            "Processed image 32/138, Loss: 0.019234424456954002\n",
            "Regression and Classification loss are 2.157899856567383 and 0.0018638401525095105\n",
            "Processed image 33/138, Loss: 0.023442838340997696\n",
            "Regression and Classification loss are 7.00358247756958 and 0.004439573734998703\n",
            "Processed image 34/138, Loss: 0.07447539269924164\n",
            "Regression and Classification loss are 1.4117822647094727 and 0.0018120508175343275\n",
            "Processed image 35/138, Loss: 0.015929872170090675\n",
            "Regression and Classification loss are 0.3403453230857849 and 0.001874630805104971\n",
            "Processed image 36/138, Loss: 0.005278083961457014\n",
            "Regression and Classification loss are 0.7053359746932983 and 0.0028921193443238735\n",
            "Processed image 37/138, Loss: 0.009945478290319443\n",
            "Regression and Classification loss are 0.9215145707130432 and 0.0018846888560801744\n",
            "Processed image 38/138, Loss: 0.011099833995103836\n",
            "Regression and Classification loss are 0.3787020146846771 and 0.002527637640014291\n",
            "Processed image 39/138, Loss: 0.006314657628536224\n",
            "Regression and Classification loss are 2.4241135120391846 and 0.004828374832868576\n",
            "Processed image 40/138, Loss: 0.029069509357213974\n",
            "Regression and Classification loss are 3.37872576713562 and 0.0012762985425069928\n",
            "Processed image 41/138, Loss: 0.03506355732679367\n",
            "Regression and Classification loss are 1.852494716644287 and 0.0047196573577821255\n",
            "Processed image 42/138, Loss: 0.023244604468345642\n",
            "Regression and Classification loss are 0.7374510169029236 and 0.0022604085970669985\n",
            "Processed image 43/138, Loss: 0.00963491853326559\n",
            "Regression and Classification loss are 0.6183321475982666 and 0.0005311320419423282\n",
            "Processed image 44/138, Loss: 0.006714452989399433\n",
            "Regression and Classification loss are 13.448042869567871 and 0.0036554106045514345\n",
            "Processed image 45/138, Loss: 0.13813583552837372\n",
            "Regression and Classification loss are 0.5928897261619568 and 0.0020599737763404846\n",
            "Processed image 46/138, Loss: 0.007988871075212955\n",
            "Regression and Classification loss are 0.37386345863342285 and 0.0038434076122939587\n",
            "Processed image 47/138, Loss: 0.007582042366266251\n",
            "Regression and Classification loss are 0.14820802211761475 and 0.005633162334561348\n",
            "Processed image 48/138, Loss: 0.007115242537111044\n",
            "Regression and Classification loss are 2.4535410404205322 and 0.006170620210468769\n",
            "Processed image 49/138, Loss: 0.030706029385328293\n",
            "Regression and Classification loss are 5.038012504577637 and 0.0035188659094274044\n",
            "Processed image 50/138, Loss: 0.05389899015426636\n",
            "Regression and Classification loss are 1.5161223411560059 and 0.001047821482643485\n",
            "Processed image 51/138, Loss: 0.016209043562412262\n",
            "Regression and Classification loss are 0.9379788637161255 and 0.0013126037083566189\n",
            "Processed image 52/138, Loss: 0.01069239154458046\n",
            "Regression and Classification loss are 0.6698520183563232 and 0.00779317319393158\n",
            "Processed image 53/138, Loss: 0.014491693116724491\n",
            "Regression and Classification loss are 0.438007116317749 and 0.004060132894665003\n",
            "Processed image 54/138, Loss: 0.008440203964710236\n",
            "Regression and Classification loss are 0.45397818088531494 and 0.003419543383643031\n",
            "Processed image 55/138, Loss: 0.00795932486653328\n",
            "Regression and Classification loss are 1.2591843605041504 and 0.004811783321201801\n",
            "Processed image 56/138, Loss: 0.017403626814484596\n",
            "Regression and Classification loss are 17.253681182861328 and 0.003255733521655202\n",
            "Processed image 57/138, Loss: 0.17579254508018494\n",
            "Regression and Classification loss are 8.688013076782227 and 0.004969176836311817\n",
            "Processed image 58/138, Loss: 0.09184930473566055\n",
            "Regression and Classification loss are 1.0455437898635864 and 0.0033998335711658\n",
            "Processed image 59/138, Loss: 0.01385527104139328\n",
            "Regression and Classification loss are 0.6901883482933044 and 0.0034377018455415964\n",
            "Processed image 60/138, Loss: 0.0103395851328969\n",
            "Regression and Classification loss are 0.9813187122344971 and 0.0019838325679302216\n",
            "Processed image 61/138, Loss: 0.01179701928049326\n",
            "Regression and Classification loss are 0.4418555200099945 and 0.0005661583854816854\n",
            "Processed image 62/138, Loss: 0.00498471362516284\n",
            "Regression and Classification loss are 1.4003632068634033 and 0.0006217632908374071\n",
            "Processed image 63/138, Loss: 0.014625394716858864\n",
            "Regression and Classification loss are 0.24637921154499054 and 0.0008186050690710545\n",
            "Processed image 64/138, Loss: 0.0032823970541357994\n",
            "Regression and Classification loss are 7.901802062988281 and 0.004598697647452354\n",
            "Processed image 65/138, Loss: 0.0836167186498642\n",
            "Regression and Classification loss are 1.4311437606811523 and 0.003140532411634922\n",
            "Processed image 66/138, Loss: 0.017451969906687737\n",
            "Regression and Classification loss are 0.4521559774875641 and 0.002787155332043767\n",
            "Processed image 67/138, Loss: 0.007308715023100376\n",
            "Regression and Classification loss are 2.2546067237854004 and 0.002333252690732479\n",
            "Processed image 68/138, Loss: 0.024879317730665207\n",
            "Regression and Classification loss are 0.13327261805534363 and 0.001731410389766097\n",
            "Processed image 69/138, Loss: 0.0030641364865005016\n",
            "Regression and Classification loss are 1.1727951765060425 and 0.001602720352821052\n",
            "Processed image 70/138, Loss: 0.013330671936273575\n",
            "Regression and Classification loss are 1.5427403450012207 and 0.0023800621274858713\n",
            "Processed image 71/138, Loss: 0.01780746504664421\n",
            "Regression and Classification loss are 0.9905908703804016 and 0.005262304097414017\n",
            "Processed image 72/138, Loss: 0.015168212354183197\n",
            "Regression and Classification loss are 0.10648080706596375 and 0.0027889811899513006\n",
            "Processed image 73/138, Loss: 0.0038537890650331974\n",
            "Regression and Classification loss are 1.390367031097412 and 0.0010258706752210855\n",
            "Processed image 74/138, Loss: 0.014929540455341339\n",
            "Regression and Classification loss are 0.42611509561538696 and 0.004278580658137798\n",
            "Processed image 75/138, Loss: 0.008539731614291668\n",
            "Regression and Classification loss are 3.298889636993408 and 0.003930323291569948\n",
            "Processed image 76/138, Loss: 0.03691921755671501\n",
            "Regression and Classification loss are 6.4131693840026855 and 0.0047377413138747215\n",
            "Processed image 77/138, Loss: 0.06886943429708481\n",
            "Regression and Classification loss are 0.07949108630418777 and 0.0033133244141936302\n",
            "Processed image 78/138, Loss: 0.004108235239982605\n",
            "Regression and Classification loss are 1.1316722631454468 and 0.0010388904483988881\n",
            "Processed image 79/138, Loss: 0.012355612590909004\n",
            "Regression and Classification loss are 2.8154549598693848 and 0.0033076468389481306\n",
            "Processed image 80/138, Loss: 0.03146219626069069\n",
            "Regression and Classification loss are 1.693655252456665 and 0.0054875509813427925\n",
            "Processed image 81/138, Loss: 0.02242410182952881\n",
            "Regression and Classification loss are 1.4689100980758667 and 0.004577639512717724\n",
            "Processed image 82/138, Loss: 0.01926673948764801\n",
            "Regression and Classification loss are 0.7218007445335388 and 0.0015523246256634593\n",
            "Processed image 83/138, Loss: 0.008770331740379333\n",
            "Regression and Classification loss are 0.9292882084846497 and 0.0046720788814127445\n",
            "Processed image 84/138, Loss: 0.013964960351586342\n",
            "Regression and Classification loss are 4.4502692222595215 and 0.004155667033046484\n",
            "Processed image 85/138, Loss: 0.048658356070518494\n",
            "Regression and Classification loss are 28.865509033203125 and 0.00234420713968575\n",
            "Processed image 86/138, Loss: 0.29099929332733154\n",
            "Regression and Classification loss are 0.40576061606407166 and 0.0014133465010672808\n",
            "Processed image 87/138, Loss: 0.0054709529504179955\n",
            "Regression and Classification loss are 1.9731621742248535 and 0.003161844564601779\n",
            "Processed image 88/138, Loss: 0.02289346605539322\n",
            "Regression and Classification loss are 1.1940677165985107 and 0.006859246641397476\n",
            "Processed image 89/138, Loss: 0.018799923360347748\n",
            "Regression and Classification loss are 0.04048847407102585 and 0.0033130513038486242\n",
            "Processed image 90/138, Loss: 0.003717936109751463\n",
            "Regression and Classification loss are 0.07444563508033752 and 0.0027546172495931387\n",
            "Processed image 91/138, Loss: 0.0034990734420716763\n",
            "Regression and Classification loss are 1.1047918796539307 and 0.004493499640375376\n",
            "Processed image 92/138, Loss: 0.01554141752421856\n",
            "Regression and Classification loss are 1.0416357517242432 and 0.0031297740060836077\n",
            "Processed image 93/138, Loss: 0.013546130619943142\n",
            "Regression and Classification loss are 1.2339050769805908 and 0.00333150546066463\n",
            "Processed image 94/138, Loss: 0.01567055657505989\n",
            "Regression and Classification loss are 0.5490966439247131 and 0.003295330563560128\n",
            "Processed image 95/138, Loss: 0.008786296471953392\n",
            "Regression and Classification loss are 16.973302841186523 and 0.006577960215508938\n",
            "Processed image 96/138, Loss: 0.1763109713792801\n",
            "Regression and Classification loss are 1.9158477783203125 and 0.004002154339104891\n",
            "Processed image 97/138, Loss: 0.023160630837082863\n",
            "Regression and Classification loss are 0.22423936426639557 and 0.0006765509024262428\n",
            "Processed image 98/138, Loss: 0.002918944461271167\n",
            "Regression and Classification loss are 5.499811172485352 and 0.004524745047092438\n",
            "Processed image 99/138, Loss: 0.059522856026887894\n",
            "Regression and Classification loss are 0.7086148262023926 and 0.001759678591042757\n",
            "Processed image 100/138, Loss: 0.008845826610922813\n",
            "Regression and Classification loss are 6.506326198577881 and 0.004869294352829456\n",
            "Processed image 101/138, Loss: 0.06993255764245987\n",
            "Regression and Classification loss are 11.292037963867188 and 0.005797478836029768\n",
            "Processed image 102/138, Loss: 0.11871784925460815\n",
            "Regression and Classification loss are 0.6890501976013184 and 0.0019805377814918756\n",
            "Processed image 103/138, Loss: 0.008871039375662804\n",
            "Regression and Classification loss are 0.6465684175491333 and 0.004083715844899416\n",
            "Processed image 104/138, Loss: 0.010549400001764297\n",
            "Regression and Classification loss are 1.1506154537200928 and 0.0017264664638787508\n",
            "Processed image 105/138, Loss: 0.013232620432972908\n",
            "Regression and Classification loss are 1.7731008529663086 and 0.003230825997889042\n",
            "Processed image 106/138, Loss: 0.020961835980415344\n",
            "Regression and Classification loss are 4.151510238647461 and 0.0016990855801850557\n",
            "Processed image 107/138, Loss: 0.043214187026023865\n",
            "Regression and Classification loss are 0.9054346680641174 and 0.0016834917478263378\n",
            "Processed image 108/138, Loss: 0.010737838223576546\n",
            "Regression and Classification loss are 1.4640357494354248 and 0.0014284647768363357\n",
            "Processed image 109/138, Loss: 0.016068821772933006\n",
            "Regression and Classification loss are 0.7681025266647339 and 0.00468550156801939\n",
            "Processed image 110/138, Loss: 0.012366526760160923\n",
            "Regression and Classification loss are 0.11638844758272171 and 0.005837288685142994\n",
            "Processed image 111/138, Loss: 0.0070011732168495655\n",
            "Regression and Classification loss are 6.429601669311523 and 0.0007930896827019751\n",
            "Processed image 112/138, Loss: 0.06508910655975342\n",
            "Regression and Classification loss are 0.5477392077445984 and 0.0005102442228235304\n",
            "Processed image 113/138, Loss: 0.005987636279314756\n",
            "Regression and Classification loss are 3.150648355484009 and 0.0009067142964340746\n",
            "Processed image 114/138, Loss: 0.03241319581866264\n",
            "Regression and Classification loss are 27.648723602294922 and 0.00445548864081502\n",
            "Processed image 115/138, Loss: 0.2809427082538605\n",
            "Regression and Classification loss are 0.9546095132827759 and 0.001794069423340261\n",
            "Processed image 116/138, Loss: 0.01134016364812851\n",
            "Regression and Classification loss are 2.204786777496338 and 0.0014460483798757195\n",
            "Processed image 117/138, Loss: 0.023493915796279907\n",
            "Regression and Classification loss are 0.29238656163215637 and 0.006007605232298374\n",
            "Processed image 118/138, Loss: 0.008931471034884453\n",
            "Regression and Classification loss are 1.4954302310943604 and 0.000687097548507154\n",
            "Processed image 119/138, Loss: 0.01564139872789383\n",
            "Regression and Classification loss are 3.2127318382263184 and 0.005563478916883469\n",
            "Processed image 120/138, Loss: 0.037690795958042145\n",
            "Regression and Classification loss are 1.0915629863739014 and 0.0032046237029135227\n",
            "Processed image 121/138, Loss: 0.014120252802968025\n",
            "Regression and Classification loss are 0.49405524134635925 and 0.003323167795315385\n",
            "Processed image 122/138, Loss: 0.008263720199465752\n",
            "Regression and Classification loss are 1.1957286596298218 and 0.0015833128709346056\n",
            "Processed image 123/138, Loss: 0.013540598563849926\n",
            "Regression and Classification loss are 63.415977478027344 and 0.005541116464883089\n",
            "Processed image 124/138, Loss: 0.6397008895874023\n",
            "Regression and Classification loss are 5.719412803649902 and 0.007173800375312567\n",
            "Processed image 125/138, Loss: 0.06436792761087418\n",
            "Regression and Classification loss are 0.5368540287017822 and 0.00250625261105597\n",
            "Processed image 126/138, Loss: 0.007874792441725731\n",
            "Regression and Classification loss are 3.752861499786377 and 0.003816797863692045\n",
            "Processed image 127/138, Loss: 0.04134541377425194\n",
            "Regression and Classification loss are 0.9688064455986023 and 0.005115946289151907\n",
            "Processed image 128/138, Loss: 0.014804011210799217\n",
            "Regression and Classification loss are 6.3127641677856445 and 0.002932212082669139\n",
            "Processed image 129/138, Loss: 0.06605985015630722\n",
            "Regression and Classification loss are 1.3042819499969482 and 0.004494163673371077\n",
            "Processed image 130/138, Loss: 0.017536982893943787\n",
            "Regression and Classification loss are 0.8096192479133606 and 0.007716197520494461\n",
            "Processed image 131/138, Loss: 0.01581238955259323\n",
            "Regression and Classification loss are 0.6799898147583008 and 0.003882213030010462\n",
            "Processed image 132/138, Loss: 0.010682111606001854\n",
            "Regression and Classification loss are 1.7741254568099976 and 0.0012421790743246675\n",
            "Processed image 133/138, Loss: 0.01898343302309513\n",
            "Regression and Classification loss are 1.435577392578125 and 0.003861507400870323\n",
            "Processed image 134/138, Loss: 0.018217280507087708\n",
            "Regression and Classification loss are 0.8513064980506897 and 0.0008746149833314121\n",
            "Processed image 135/138, Loss: 0.00938768032938242\n",
            "Regression and Classification loss are 0.5681578516960144 and 0.0008084570872597396\n",
            "Processed image 136/138, Loss: 0.006490035448223352\n",
            "Regression and Classification loss are 0.7695528268814087 and 0.001988361356779933\n",
            "Processed image 137/138, Loss: 0.009683889336884022\n",
            "Regression and Classification loss are 1.2631371021270752 and 0.0006433951784856617\n",
            "Processed image 138/138, Loss: 0.013274765573441982\n",
            "Epoch 2/50, Average Loss: 0.03549542995861502\n",
            "Regression and Classification loss are 0.9335541725158691 and 0.008215544745326042\n",
            "Processed image 1/138, Loss: 0.017551086843013763\n",
            "Regression and Classification loss are 0.28749963641166687 and 0.002709355903789401\n",
            "Processed image 2/138, Loss: 0.005584352184087038\n",
            "Regression and Classification loss are 0.13578742742538452 and 0.014536680653691292\n",
            "Processed image 3/138, Loss: 0.015894554555416107\n",
            "Regression and Classification loss are 0.6610883474349976 and 0.007749661803245544\n",
            "Processed image 4/138, Loss: 0.014360545203089714\n",
            "Regression and Classification loss are 0.5425244569778442 and 0.0023974659852683544\n",
            "Processed image 5/138, Loss: 0.007822711020708084\n",
            "Regression and Classification loss are 1.706926941871643 and 0.0032547113951295614\n",
            "Processed image 6/138, Loss: 0.0203239805996418\n",
            "Regression and Classification loss are 0.6046217083930969 and 0.003889634506776929\n",
            "Processed image 7/138, Loss: 0.009935851208865643\n",
            "Regression and Classification loss are 0.1485643833875656 and 0.0037158539053052664\n",
            "Processed image 8/138, Loss: 0.005201497580856085\n",
            "Regression and Classification loss are 32.857139587402344 and 0.004792169202119112\n",
            "Processed image 9/138, Loss: 0.3333635628223419\n",
            "Regression and Classification loss are 0.5023242235183716 and 0.007735359948128462\n",
            "Processed image 10/138, Loss: 0.01275860145688057\n",
            "Regression and Classification loss are 0.1475483477115631 and 0.005286585073918104\n",
            "Processed image 11/138, Loss: 0.006762068718671799\n",
            "Regression and Classification loss are 9.054795265197754 and 0.002998513402417302\n",
            "Processed image 12/138, Loss: 0.09354646503925323\n",
            "Regression and Classification loss are 0.6725337505340576 and 0.0005146145122125745\n",
            "Processed image 13/138, Loss: 0.007239951752126217\n",
            "Regression and Classification loss are 1.07393479347229 and 0.007074832450598478\n",
            "Processed image 14/138, Loss: 0.01781417988240719\n",
            "Regression and Classification loss are 0.7234559655189514 and 0.0014361984794959426\n",
            "Processed image 15/138, Loss: 0.00867075752466917\n",
            "Regression and Classification loss are 1.212175726890564 and 0.0010283581214025617\n",
            "Processed image 16/138, Loss: 0.013150114566087723\n",
            "Regression and Classification loss are 0.44419217109680176 and 0.00045145777403376997\n",
            "Processed image 17/138, Loss: 0.004893379285931587\n",
            "Regression and Classification loss are 0.5752274394035339 and 0.003932877443730831\n",
            "Processed image 18/138, Loss: 0.009685151278972626\n",
            "Regression and Classification loss are 2.939011812210083 and 0.001498951343819499\n",
            "Processed image 19/138, Loss: 0.03088906779885292\n",
            "Regression and Classification loss are 2.1644904613494873 and 0.0005505088483914733\n",
            "Processed image 20/138, Loss: 0.02219541184604168\n",
            "Regression and Classification loss are 1.1134862899780273 and 0.0036008290480822325\n",
            "Processed image 21/138, Loss: 0.01473569218069315\n",
            "Regression and Classification loss are 0.5759310722351074 and 0.0036380745004862547\n",
            "Processed image 22/138, Loss: 0.009397384710609913\n",
            "Regression and Classification loss are 1.104485034942627 and 0.012917378917336464\n",
            "Processed image 23/138, Loss: 0.02396222949028015\n",
            "Regression and Classification loss are 1.053834319114685 and 0.00297712255269289\n",
            "Processed image 24/138, Loss: 0.013515465892851353\n",
            "Regression and Classification loss are 15.921863555908203 and 0.003524970030412078\n",
            "Processed image 25/138, Loss: 0.16274361312389374\n",
            "Regression and Classification loss are 3.6225674152374268 and 0.0015884304884821177\n",
            "Processed image 26/138, Loss: 0.037814103066921234\n",
            "Regression and Classification loss are 2.408255100250244 and 0.006075593642890453\n",
            "Processed image 27/138, Loss: 0.030158143490552902\n",
            "Regression and Classification loss are 1.2397425174713135 and 0.001178002799861133\n",
            "Processed image 28/138, Loss: 0.013575428165495396\n",
            "Regression and Classification loss are 0.5540032386779785 and 0.002226258395239711\n",
            "Processed image 29/138, Loss: 0.007766290567815304\n",
            "Regression and Classification loss are 7.8657546043396 and 0.003381740301847458\n",
            "Processed image 30/138, Loss: 0.08203928172588348\n",
            "Regression and Classification loss are 0.19781538844108582 and 0.0039688716642558575\n",
            "Processed image 31/138, Loss: 0.005947025492787361\n",
            "Regression and Classification loss are 1.3658736944198608 and 0.0002578927087597549\n",
            "Processed image 32/138, Loss: 0.013916629366576672\n",
            "Regression and Classification loss are 1.7175604104995728 and 0.003620592877268791\n",
            "Processed image 33/138, Loss: 0.020796196535229683\n",
            "Regression and Classification loss are 1.4472428560256958 and 0.001509734895080328\n",
            "Processed image 34/138, Loss: 0.015982162207365036\n",
            "Regression and Classification loss are 0.8656823635101318 and 0.0049700126983225346\n",
            "Processed image 35/138, Loss: 0.013626836240291595\n",
            "Regression and Classification loss are 0.20998194813728333 and 0.002632529940456152\n",
            "Processed image 36/138, Loss: 0.004732349421828985\n",
            "Regression and Classification loss are 0.6286926865577698 and 0.003359270514920354\n",
            "Processed image 37/138, Loss: 0.009646196849644184\n",
            "Regression and Classification loss are 0.9178722500801086 and 0.001192313153296709\n",
            "Processed image 38/138, Loss: 0.01037103496491909\n",
            "Regression and Classification loss are 0.19670206308364868 and 0.004089947324246168\n",
            "Processed image 39/138, Loss: 0.006056968122720718\n",
            "Regression and Classification loss are 0.885613739490509 and 0.008052879944443703\n",
            "Processed image 40/138, Loss: 0.01690901815891266\n",
            "Regression and Classification loss are 1.452514886856079 and 0.0016939124325290322\n",
            "Processed image 41/138, Loss: 0.016219060868024826\n",
            "Regression and Classification loss are 2.6856534481048584 and 0.0025007815565913916\n",
            "Processed image 42/138, Loss: 0.029357315972447395\n",
            "Regression and Classification loss are 0.4361652433872223 and 0.0009757066145539284\n",
            "Processed image 43/138, Loss: 0.005337358918040991\n",
            "Regression and Classification loss are 0.6262935400009155 and 0.0009217872866429389\n",
            "Processed image 44/138, Loss: 0.00718472246080637\n",
            "Regression and Classification loss are 12.796902656555176 and 0.0004291406075935811\n",
            "Processed image 45/138, Loss: 0.12839816510677338\n",
            "Regression and Classification loss are 0.7966329455375671 and 0.005145244766026735\n",
            "Processed image 46/138, Loss: 0.013111574575304985\n",
            "Regression and Classification loss are 0.29632389545440674 and 0.0035911486484110355\n",
            "Processed image 47/138, Loss: 0.0065543875098228455\n",
            "Regression and Classification loss are 0.324616014957428 and 0.002678956836462021\n",
            "Processed image 48/138, Loss: 0.005925117060542107\n",
            "Regression and Classification loss are 2.1608595848083496 and 0.0055784378200769424\n",
            "Processed image 49/138, Loss: 0.027187032625079155\n",
            "Regression and Classification loss are 5.004690170288086 and 0.0032009342685341835\n",
            "Processed image 50/138, Loss: 0.053247835487127304\n",
            "Regression and Classification loss are 1.3483607769012451 and 0.0016119338106364012\n",
            "Processed image 51/138, Loss: 0.015095541253685951\n",
            "Regression and Classification loss are 0.8420107364654541 and 0.002825504634529352\n",
            "Processed image 52/138, Loss: 0.011245612055063248\n",
            "Regression and Classification loss are 0.5191553831100464 and 0.001473274896852672\n",
            "Processed image 53/138, Loss: 0.006664828862994909\n",
            "Regression and Classification loss are 8.86737060546875 and 0.0032089438755065203\n",
            "Processed image 54/138, Loss: 0.09188264608383179\n",
            "Regression and Classification loss are 0.31032299995422363 and 0.0021002991124987602\n",
            "Processed image 55/138, Loss: 0.0052035292610526085\n",
            "Regression and Classification loss are 1.2635183334350586 and 0.0031399286817759275\n",
            "Processed image 56/138, Loss: 0.015775110572576523\n",
            "Regression and Classification loss are 17.465049743652344 and 0.0034991896245628595\n",
            "Processed image 57/138, Loss: 0.17814968526363373\n",
            "Regression and Classification loss are 1.4557605981826782 and 0.0018803984858095646\n",
            "Processed image 58/138, Loss: 0.01643800362944603\n",
            "Regression and Classification loss are 1.8802881240844727 and 0.002216489752754569\n",
            "Processed image 59/138, Loss: 0.02101937122642994\n",
            "Regression and Classification loss are 0.6036893129348755 and 0.003248165361583233\n",
            "Processed image 60/138, Loss: 0.009285058826208115\n",
            "Regression and Classification loss are 1.062462329864502 and 0.002513265935704112\n",
            "Processed image 61/138, Loss: 0.013137889094650745\n",
            "Regression and Classification loss are 0.6194499731063843 and 0.009026296436786652\n",
            "Processed image 62/138, Loss: 0.015220796689391136\n",
            "Regression and Classification loss are 2.8818657398223877 and 0.0011392137967050076\n",
            "Processed image 63/138, Loss: 0.02995787188410759\n",
            "Regression and Classification loss are 0.3465169668197632 and 0.0037408757489174604\n",
            "Processed image 64/138, Loss: 0.007206045091152191\n",
            "Regression and Classification loss are 5.922931671142578 and 0.005075922701507807\n",
            "Processed image 65/138, Loss: 0.06430523842573166\n",
            "Regression and Classification loss are 0.4888269901275635 and 0.004593362100422382\n",
            "Processed image 66/138, Loss: 0.009481631219387054\n",
            "Regression and Classification loss are 0.09356202930212021 and 0.001302241929806769\n",
            "Processed image 67/138, Loss: 0.0022378622088581324\n",
            "Regression and Classification loss are 0.7359630465507507 and 0.0051557039842009544\n",
            "Processed image 68/138, Loss: 0.012515334412455559\n",
            "Regression and Classification loss are 0.3934226632118225 and 0.0055517833679914474\n",
            "Processed image 69/138, Loss: 0.009486010298132896\n",
            "Regression and Classification loss are 1.550150990486145 and 0.001092642662115395\n",
            "Processed image 70/138, Loss: 0.01659415289759636\n",
            "Regression and Classification loss are 0.580256998538971 and 0.003196551464498043\n",
            "Processed image 71/138, Loss: 0.008999121375381947\n",
            "Regression and Classification loss are 0.19393758475780487 and 0.005473523400723934\n",
            "Processed image 72/138, Loss: 0.007412899285554886\n",
            "Regression and Classification loss are 0.39642617106437683 and 0.0015728932339698076\n",
            "Processed image 73/138, Loss: 0.005537155084311962\n",
            "Regression and Classification loss are 0.9961850643157959 and 0.0014239851152524352\n",
            "Processed image 74/138, Loss: 0.011385834775865078\n",
            "Regression and Classification loss are 0.4625963568687439 and 0.003964203409850597\n",
            "Processed image 75/138, Loss: 0.00859016738831997\n",
            "Regression and Classification loss are 3.6507680416107178 and 0.002392358612269163\n",
            "Processed image 76/138, Loss: 0.038900040090084076\n",
            "Regression and Classification loss are 6.820746421813965 and 0.007648032158613205\n",
            "Processed image 77/138, Loss: 0.07585549354553223\n",
            "Regression and Classification loss are 0.2043628990650177 and 0.003548647044226527\n",
            "Processed image 78/138, Loss: 0.0055922758765518665\n",
            "Regression and Classification loss are 1.07148277759552 and 0.005108355078846216\n",
            "Processed image 79/138, Loss: 0.015823181718587875\n",
            "Regression and Classification loss are 2.2575204372406006 and 0.0019993605092167854\n",
            "Processed image 80/138, Loss: 0.024574562907218933\n",
            "Regression and Classification loss are 1.4901244640350342 and 0.002132261171936989\n",
            "Processed image 81/138, Loss: 0.01703350618481636\n",
            "Regression and Classification loss are 0.9888753890991211 and 0.005015168339014053\n",
            "Processed image 82/138, Loss: 0.014903921633958817\n",
            "Regression and Classification loss are 0.9655495285987854 and 0.001058062189258635\n",
            "Processed image 83/138, Loss: 0.010713557712733746\n",
            "Regression and Classification loss are 0.40467381477355957 and 0.011499455198645592\n",
            "Processed image 84/138, Loss: 0.015546193346381187\n",
            "Regression and Classification loss are 5.84151029586792 and 0.003609435399994254\n",
            "Processed image 85/138, Loss: 0.06202453374862671\n",
            "Regression and Classification loss are 29.554574966430664 and 0.003404394257813692\n",
            "Processed image 86/138, Loss: 0.2989501655101776\n",
            "Regression and Classification loss are 0.42845118045806885 and 0.001351775717921555\n",
            "Processed image 87/138, Loss: 0.00563628738746047\n",
            "Regression and Classification loss are 1.9045898914337158 and 0.0008817106718197465\n",
            "Processed image 88/138, Loss: 0.019927609711885452\n",
            "Regression and Classification loss are 3.0133190155029297 and 0.003057723632082343\n",
            "Processed image 89/138, Loss: 0.03319091349840164\n",
            "Regression and Classification loss are 0.0762280523777008 and 0.0031034904532134533\n",
            "Processed image 90/138, Loss: 0.003865770995616913\n",
            "Regression and Classification loss are 0.1874670535326004 and 0.00367861520498991\n",
            "Processed image 91/138, Loss: 0.005553285591304302\n",
            "Regression and Classification loss are 1.2061142921447754 and 0.0045371935702860355\n",
            "Processed image 92/138, Loss: 0.016598336398601532\n",
            "Regression and Classification loss are 0.9986568093299866 and 0.0020727580413222313\n",
            "Processed image 93/138, Loss: 0.012059326283633709\n",
            "Regression and Classification loss are 1.4715237617492676 and 0.0034241098910570145\n",
            "Processed image 94/138, Loss: 0.018139347434043884\n",
            "Regression and Classification loss are 0.48569828271865845 and 0.004458392970263958\n",
            "Processed image 95/138, Loss: 0.009315375238656998\n",
            "Regression and Classification loss are 4.754589557647705 and 0.0032734465785324574\n",
            "Processed image 96/138, Loss: 0.05081934109330177\n",
            "Regression and Classification loss are 0.6838843822479248 and 0.0069653429090976715\n",
            "Processed image 97/138, Loss: 0.013804186135530472\n",
            "Regression and Classification loss are 0.19751392304897308 and 0.00041895906906574965\n",
            "Processed image 98/138, Loss: 0.002394098322838545\n",
            "Regression and Classification loss are 4.482560157775879 and 0.0030850106850266457\n",
            "Processed image 99/138, Loss: 0.04791061207652092\n",
            "Regression and Classification loss are 0.8709510564804077 and 0.0017091452609747648\n",
            "Processed image 100/138, Loss: 0.010418656282126904\n",
            "Regression and Classification loss are 1.1775621175765991 and 0.0022154778707772493\n",
            "Processed image 101/138, Loss: 0.0139910988509655\n",
            "Regression and Classification loss are 5.92488956451416 and 0.0035064073745161295\n",
            "Processed image 102/138, Loss: 0.06275530159473419\n",
            "Regression and Classification loss are 0.39447665214538574 and 0.0022467977833002806\n",
            "Processed image 103/138, Loss: 0.006191563792526722\n",
            "Regression and Classification loss are 1.2448663711547852 and 0.004795074928551912\n",
            "Processed image 104/138, Loss: 0.01724373921751976\n",
            "Regression and Classification loss are 1.1666593551635742 and 0.0011393012246116996\n",
            "Processed image 105/138, Loss: 0.012805894017219543\n",
            "Regression and Classification loss are 5.032986164093018 and 0.0034791333600878716\n",
            "Processed image 106/138, Loss: 0.053808994591236115\n",
            "Regression and Classification loss are 2.3445582389831543 and 0.0024478829000145197\n",
            "Processed image 107/138, Loss: 0.02589346468448639\n",
            "Regression and Classification loss are 0.8629422187805176 and 0.004627665970474482\n",
            "Processed image 108/138, Loss: 0.013257088139653206\n",
            "Regression and Classification loss are 1.1447621583938599 and 0.0018755393102765083\n",
            "Processed image 109/138, Loss: 0.013323160819709301\n",
            "Regression and Classification loss are 0.114328533411026 and 0.002352338982746005\n",
            "Processed image 110/138, Loss: 0.003495624288916588\n",
            "Regression and Classification loss are 1.4422786235809326 and 0.0042160069569945335\n",
            "Processed image 111/138, Loss: 0.018638793379068375\n",
            "Regression and Classification loss are 6.741333484649658 and 0.00035884082899428904\n",
            "Processed image 112/138, Loss: 0.06777217239141464\n",
            "Regression and Classification loss are 0.6562547087669373 and 0.0013587523717433214\n",
            "Processed image 113/138, Loss: 0.00792129896581173\n",
            "Regression and Classification loss are 3.1835074424743652 and 0.0006896494887769222\n",
            "Processed image 114/138, Loss: 0.032524723559617996\n",
            "Regression and Classification loss are 30.065122604370117 and 0.0012918035499751568\n",
            "Processed image 115/138, Loss: 0.3019430339336395\n",
            "Regression and Classification loss are 0.5847105979919434 and 0.0016503988299518824\n",
            "Processed image 116/138, Loss: 0.007497504353523254\n",
            "Regression and Classification loss are 3.7071478366851807 and 0.005179154220968485\n",
            "Processed image 117/138, Loss: 0.042250633239746094\n",
            "Regression and Classification loss are 0.3755367696285248 and 0.0017975377850234509\n",
            "Processed image 118/138, Loss: 0.005552905611693859\n",
            "Regression and Classification loss are 1.349209189414978 and 0.0003493587428238243\n",
            "Processed image 119/138, Loss: 0.013841450214385986\n",
            "Regression and Classification loss are 3.1815435886383057 and 0.011659568175673485\n",
            "Processed image 120/138, Loss: 0.04347500205039978\n",
            "Regression and Classification loss are 0.5432513952255249 and 0.009135919623076916\n",
            "Processed image 121/138, Loss: 0.014568433165550232\n",
            "Regression and Classification loss are 0.7310671210289001 and 0.0031714141368865967\n",
            "Processed image 122/138, Loss: 0.01048208586871624\n",
            "Regression and Classification loss are 1.4499263763427734 and 0.006098441779613495\n",
            "Processed image 123/138, Loss: 0.020597705617547035\n",
            "Regression and Classification loss are 66.08301544189453 and 0.0035415494348853827\n",
            "Processed image 124/138, Loss: 0.66437166929245\n",
            "Regression and Classification loss are 5.700249195098877 and 0.003389997873455286\n",
            "Processed image 125/138, Loss: 0.06039249151945114\n",
            "Regression and Classification loss are 0.87955641746521 and 0.0020787441171705723\n",
            "Processed image 126/138, Loss: 0.01087430864572525\n",
            "Regression and Classification loss are 3.4777579307556152 and 0.0003896105336025357\n",
            "Processed image 127/138, Loss: 0.035167187452316284\n",
            "Regression and Classification loss are 0.8282690048217773 and 0.0023457747884094715\n",
            "Processed image 128/138, Loss: 0.010628465563058853\n",
            "Regression and Classification loss are 6.187261581420898 and 0.004872226156294346\n",
            "Processed image 129/138, Loss: 0.0667448416352272\n",
            "Regression and Classification loss are 30.434959411621094 and 0.0037900570314377546\n",
            "Processed image 130/138, Loss: 0.3081396520137787\n",
            "Regression and Classification loss are 0.9094452857971191 and 0.003516525961458683\n",
            "Processed image 131/138, Loss: 0.012610978446900845\n",
            "Regression and Classification loss are 1.5359512567520142 and 0.0009596822201274335\n",
            "Processed image 132/138, Loss: 0.016319194808602333\n",
            "Regression and Classification loss are 1.530203104019165 and 0.0017187412595376372\n",
            "Processed image 133/138, Loss: 0.01702077127993107\n",
            "Regression and Classification loss are 1.967786192893982 and 0.00535760261118412\n",
            "Processed image 134/138, Loss: 0.025035463273525238\n",
            "Regression and Classification loss are 0.7686907052993774 and 0.0009955381974577904\n",
            "Processed image 135/138, Loss: 0.00868244469165802\n",
            "Regression and Classification loss are 1.0279479026794434 and 0.000757052970584482\n",
            "Processed image 136/138, Loss: 0.011036531068384647\n",
            "Regression and Classification loss are 0.7959849834442139 and 0.0012055604020133615\n",
            "Processed image 137/138, Loss: 0.009165409952402115\n",
            "Regression and Classification loss are 1.207690715789795 and 0.0007221567793749273\n",
            "Processed image 138/138, Loss: 0.012799063697457314\n",
            "Epoch 3/50, Average Loss: 0.03597866690656899\n",
            "Regression and Classification loss are 1.46854567527771 and 0.004421700723469257\n",
            "Processed image 1/138, Loss: 0.019107157364487648\n",
            "Regression and Classification loss are 0.18171535432338715 and 0.0005832237075082958\n",
            "Processed image 2/138, Loss: 0.0024003772996366024\n",
            "Regression and Classification loss are 0.06463193893432617 and 0.015496053732931614\n",
            "Processed image 3/138, Loss: 0.01614237390458584\n",
            "Regression and Classification loss are 0.5342354774475098 and 0.004161579068750143\n",
            "Processed image 4/138, Loss: 0.009503933601081371\n",
            "Regression and Classification loss are 0.24240118265151978 and 0.0005635925335809588\n",
            "Processed image 5/138, Loss: 0.0029876041226089\n",
            "Regression and Classification loss are 1.7389861345291138 and 0.0031064755748957396\n",
            "Processed image 6/138, Loss: 0.020496336743235588\n",
            "Regression and Classification loss are 1.0942455530166626 and 0.0038420308846980333\n",
            "Processed image 7/138, Loss: 0.014784486033022404\n",
            "Regression and Classification loss are 0.14381256699562073 and 0.004065067507326603\n",
            "Processed image 8/138, Loss: 0.005503193009644747\n",
            "Regression and Classification loss are 64.4869613647461 and 0.005030847620218992\n",
            "Processed image 9/138, Loss: 0.649900496006012\n",
            "Regression and Classification loss are 0.5600489377975464 and 0.0016015851870179176\n",
            "Processed image 10/138, Loss: 0.007202074397355318\n",
            "Regression and Classification loss are 0.39724287390708923 and 0.0019902701023966074\n",
            "Processed image 11/138, Loss: 0.005962698720395565\n",
            "Regression and Classification loss are 6.407717227935791 and 0.0020971514750272036\n",
            "Processed image 12/138, Loss: 0.06617432087659836\n",
            "Regression and Classification loss are 1.14121413230896 and 0.0023954925127327442\n",
            "Processed image 13/138, Loss: 0.013807633891701698\n",
            "Regression and Classification loss are 0.8958668112754822 and 0.009209751151502132\n",
            "Processed image 14/138, Loss: 0.01816841959953308\n",
            "Regression and Classification loss are 0.7063124179840088 and 0.001414019614458084\n",
            "Processed image 15/138, Loss: 0.008477143943309784\n",
            "Regression and Classification loss are 0.9775543808937073 and 0.0059743099845945835\n",
            "Processed image 16/138, Loss: 0.01574985310435295\n",
            "Regression and Classification loss are 0.19355900585651398 and 0.00033064300077967346\n",
            "Processed image 17/138, Loss: 0.0022662330884486437\n",
            "Regression and Classification loss are 0.610100269317627 and 0.002930557122454047\n",
            "Processed image 18/138, Loss: 0.009031559340655804\n",
            "Regression and Classification loss are 3.1062448024749756 and 0.0011038236552849412\n",
            "Processed image 19/138, Loss: 0.032166268676519394\n",
            "Regression and Classification loss are 1.5426628589630127 and 0.001529062632471323\n",
            "Processed image 20/138, Loss: 0.01695569045841694\n",
            "Regression and Classification loss are 1.2421784400939941 and 0.004099730867892504\n",
            "Processed image 21/138, Loss: 0.0165215153247118\n",
            "Regression and Classification loss are 0.6819390058517456 and 0.0034759053960442543\n",
            "Processed image 22/138, Loss: 0.010295295156538486\n",
            "Regression and Classification loss are 1.163346529006958 and 0.011318307369947433\n",
            "Processed image 23/138, Loss: 0.022951772436499596\n",
            "Regression and Classification loss are 1.0709257125854492 and 0.002291792770847678\n",
            "Processed image 24/138, Loss: 0.013001049868762493\n",
            "Regression and Classification loss are 16.399877548217773 and 0.0007238303660415113\n",
            "Processed image 25/138, Loss: 0.16472259163856506\n",
            "Regression and Classification loss are 3.7837467193603516 and 0.003992706071585417\n",
            "Processed image 26/138, Loss: 0.04183017462491989\n",
            "Regression and Classification loss are 1.3398137092590332 and 0.0033833147026598454\n",
            "Processed image 27/138, Loss: 0.016781451180577278\n",
            "Regression and Classification loss are 1.2527025938034058 and 0.001067614066414535\n",
            "Processed image 28/138, Loss: 0.013594639487564564\n",
            "Regression and Classification loss are 0.32142579555511475 and 0.003649994730949402\n",
            "Processed image 29/138, Loss: 0.006864252500236034\n",
            "Regression and Classification loss are 7.454395771026611 and 0.0022685586009174585\n",
            "Processed image 30/138, Loss: 0.0768125131726265\n",
            "Regression and Classification loss are 0.16969196498394012 and 0.004826858639717102\n",
            "Processed image 31/138, Loss: 0.006523778196424246\n",
            "Regression and Classification loss are 1.4488441944122314 and 0.0004164815181866288\n",
            "Processed image 32/138, Loss: 0.014904923737049103\n",
            "Regression and Classification loss are 3.6969897747039795 and 0.0038297451101243496\n",
            "Processed image 33/138, Loss: 0.040799640119075775\n",
            "Regression and Classification loss are 1.38553786277771 and 0.0029800457414239645\n",
            "Processed image 34/138, Loss: 0.016835423186421394\n",
            "Regression and Classification loss are 1.3612866401672363 and 0.0013958722120150924\n",
            "Processed image 35/138, Loss: 0.01500873826444149\n",
            "Regression and Classification loss are 0.41563960909843445 and 0.001292369095608592\n",
            "Processed image 36/138, Loss: 0.005448765121400356\n",
            "Regression and Classification loss are 0.5984789729118347 and 0.004087384790182114\n",
            "Processed image 37/138, Loss: 0.010072174482047558\n",
            "Regression and Classification loss are 1.2920728921890259 and 0.0007271866779774427\n",
            "Processed image 38/138, Loss: 0.013647915795445442\n",
            "Regression and Classification loss are 0.2619745135307312 and 0.004028524272143841\n",
            "Processed image 39/138, Loss: 0.006648269481956959\n",
            "Regression and Classification loss are 0.3832046687602997 and 0.003611221443861723\n",
            "Processed image 40/138, Loss: 0.007443267852067947\n",
            "Regression and Classification loss are 1.1489229202270508 and 0.0013668470783159137\n",
            "Processed image 41/138, Loss: 0.01285607647150755\n",
            "Regression and Classification loss are 1.5951004028320312 and 0.004616922698915005\n",
            "Processed image 42/138, Loss: 0.02056792750954628\n",
            "Regression and Classification loss are 0.6496058106422424 and 0.0015898779965937138\n",
            "Processed image 43/138, Loss: 0.008085936307907104\n",
            "Regression and Classification loss are 0.5574600696563721 and 0.0003837882250081748\n",
            "Processed image 44/138, Loss: 0.005958389025181532\n",
            "Regression and Classification loss are 12.696858406066895 and 0.0007826075307093561\n",
            "Processed image 45/138, Loss: 0.1277511864900589\n",
            "Regression and Classification loss are 0.5718846917152405 and 0.0020414856262505054\n",
            "Processed image 46/138, Loss: 0.007760332431644201\n",
            "Regression and Classification loss are 0.4998301863670349 and 0.0066603729501366615\n",
            "Processed image 47/138, Loss: 0.011658674106001854\n",
            "Regression and Classification loss are 0.2589697241783142 and 0.0063878926448524\n",
            "Processed image 48/138, Loss: 0.008977590128779411\n",
            "Regression and Classification loss are 2.4788026809692383 and 0.005860935430973768\n",
            "Processed image 49/138, Loss: 0.030648961663246155\n",
            "Regression and Classification loss are 5.338900566101074 and 0.004782089497894049\n",
            "Processed image 50/138, Loss: 0.058171093463897705\n",
            "Regression and Classification loss are 1.5386916399002075 and 0.0023870044387876987\n",
            "Processed image 51/138, Loss: 0.01777392067015171\n",
            "Regression and Classification loss are 0.2512350082397461 and 0.006333685014396906\n",
            "Processed image 52/138, Loss: 0.008846035227179527\n",
            "Regression and Classification loss are 0.6057157516479492 and 0.0012629617704078555\n",
            "Processed image 53/138, Loss: 0.007320119068026543\n",
            "Regression and Classification loss are 1.12619948387146 and 0.003863353980705142\n",
            "Processed image 54/138, Loss: 0.015125349164009094\n",
            "Regression and Classification loss are 0.20566517114639282 and 0.000522144022397697\n",
            "Processed image 55/138, Loss: 0.00257879588752985\n",
            "Regression and Classification loss are 1.1126371622085571 and 0.007612273097038269\n",
            "Processed image 56/138, Loss: 0.0187386441975832\n",
            "Regression and Classification loss are 3.5868115425109863 and 0.004203445743769407\n",
            "Processed image 57/138, Loss: 0.04007156193256378\n",
            "Regression and Classification loss are 1.9460638761520386 and 0.0032931137830018997\n",
            "Processed image 58/138, Loss: 0.022753752768039703\n",
            "Regression and Classification loss are 0.8225694298744202 and 0.005085267126560211\n",
            "Processed image 59/138, Loss: 0.013310961425304413\n",
            "Regression and Classification loss are 0.5124291181564331 and 0.0036813810002058744\n",
            "Processed image 60/138, Loss: 0.008805671706795692\n",
            "Regression and Classification loss are 0.4846396744251251 and 0.005521478597074747\n",
            "Processed image 61/138, Loss: 0.010367875918745995\n",
            "Regression and Classification loss are 0.16270112991333008 and 0.0004778709262609482\n",
            "Processed image 62/138, Loss: 0.002104882150888443\n",
            "Regression and Classification loss are 1.3544771671295166 and 0.0009524080087430775\n",
            "Processed image 63/138, Loss: 0.014497179538011551\n",
            "Regression and Classification loss are 0.41343778371810913 and 0.000663101498503238\n",
            "Processed image 64/138, Loss: 0.0047974796034395695\n",
            "Regression and Classification loss are 6.62680721282959 and 0.002536015585064888\n",
            "Processed image 65/138, Loss: 0.06880408525466919\n",
            "Regression and Classification loss are 1.0334315299987793 and 0.004524729680269957\n",
            "Processed image 66/138, Loss: 0.014859044924378395\n",
            "Regression and Classification loss are 0.05545851215720177 and 0.0010637642117217183\n",
            "Processed image 67/138, Loss: 0.0016183493426069617\n",
            "Regression and Classification loss are 0.29275649785995483 and 0.006103490479290485\n",
            "Processed image 68/138, Loss: 0.009031055495142937\n",
            "Regression and Classification loss are 0.5697175860404968 and 0.0027268819976598024\n",
            "Processed image 69/138, Loss: 0.008424057625234127\n",
            "Regression and Classification loss are 1.9723893404006958 and 0.0022860176395624876\n",
            "Processed image 70/138, Loss: 0.02200990915298462\n",
            "Regression and Classification loss are 1.0714192390441895 and 0.0035443094093352556\n",
            "Processed image 71/138, Loss: 0.01425850111991167\n",
            "Regression and Classification loss are 0.29036611318588257 and 0.0028104661032557487\n",
            "Processed image 72/138, Loss: 0.005714126862585545\n",
            "Regression and Classification loss are 0.742577314376831 and 0.002867054892703891\n",
            "Processed image 73/138, Loss: 0.01029282808303833\n",
            "Regression and Classification loss are 0.9522047638893127 and 0.0007751869270578027\n",
            "Processed image 74/138, Loss: 0.01029723510146141\n",
            "Regression and Classification loss are 0.9618579745292664 and 0.003142948029562831\n",
            "Processed image 75/138, Loss: 0.012761527672410011\n",
            "Regression and Classification loss are 3.090682029724121 and 0.003942446783185005\n",
            "Processed image 76/138, Loss: 0.03484926372766495\n",
            "Regression and Classification loss are 5.981510639190674 and 0.005111983977258205\n",
            "Processed image 77/138, Loss: 0.06492708623409271\n",
            "Regression and Classification loss are 0.33027786016464233 and 0.007888717576861382\n",
            "Processed image 78/138, Loss: 0.01119149662554264\n",
            "Regression and Classification loss are 2.168031930923462 and 0.0076357475481927395\n",
            "Processed image 79/138, Loss: 0.029316067695617676\n",
            "Regression and Classification loss are 2.3066463470458984 and 0.0020800763741135597\n",
            "Processed image 80/138, Loss: 0.025146540254354477\n",
            "Regression and Classification loss are 1.6706273555755615 and 0.005091680213809013\n",
            "Processed image 81/138, Loss: 0.02179795317351818\n",
            "Regression and Classification loss are 0.6900032758712769 and 0.004965778440237045\n",
            "Processed image 82/138, Loss: 0.011865811422467232\n",
            "Regression and Classification loss are 0.5512629151344299 and 0.0027281439397484064\n",
            "Processed image 83/138, Loss: 0.008240773342549801\n",
            "Regression and Classification loss are 0.5300705432891846 and 0.01032301690429449\n",
            "Processed image 84/138, Loss: 0.015623722225427628\n",
            "Regression and Classification loss are 7.0433268547058105 and 0.003927794750779867\n",
            "Processed image 85/138, Loss: 0.07436106353998184\n",
            "Regression and Classification loss are 32.88240432739258 and 0.0032419513445347548\n",
            "Processed image 86/138, Loss: 0.33206599950790405\n",
            "Regression and Classification loss are 0.3221696615219116 and 0.0024164370261132717\n",
            "Processed image 87/138, Loss: 0.005638133734464645\n",
            "Regression and Classification loss are 1.772011160850525 and 0.0015931848902255297\n",
            "Processed image 88/138, Loss: 0.019313296303153038\n",
            "Regression and Classification loss are 0.8777715563774109 and 0.006066939327865839\n",
            "Processed image 89/138, Loss: 0.014844654127955437\n",
            "Regression and Classification loss are 0.3194391131401062 and 0.002999599790200591\n",
            "Processed image 90/138, Loss: 0.00619399081915617\n",
            "Regression and Classification loss are 0.2519909143447876 and 0.0007187641458585858\n",
            "Processed image 91/138, Loss: 0.003238673321902752\n",
            "Regression and Classification loss are 0.9606561660766602 and 0.004699417855590582\n",
            "Processed image 92/138, Loss: 0.014305979013442993\n",
            "Regression and Classification loss are 0.9736313223838806 and 0.002202807692810893\n",
            "Processed image 93/138, Loss: 0.01193912047892809\n",
            "Regression and Classification loss are 1.4435514211654663 and 0.004006590694189072\n",
            "Processed image 94/138, Loss: 0.018442105501890182\n",
            "Regression and Classification loss are 0.6197139620780945 and 0.0033673387952148914\n",
            "Processed image 95/138, Loss: 0.009564477950334549\n",
            "Regression and Classification loss are 9.172118186950684 and 0.003136751940473914\n",
            "Processed image 96/138, Loss: 0.09485793113708496\n",
            "Regression and Classification loss are 1.864708662033081 and 0.00513934763148427\n",
            "Processed image 97/138, Loss: 0.023786433041095734\n",
            "Regression and Classification loss are 0.33764567971229553 and 0.0006538274465128779\n",
            "Processed image 98/138, Loss: 0.004030284006148577\n",
            "Regression and Classification loss are 244.7880401611328 and 0.004585490562021732\n",
            "Processed image 99/138, Loss: 2.452465772628784\n",
            "Regression and Classification loss are 1.2212215662002563 and 0.0030423954594880342\n",
            "Processed image 100/138, Loss: 0.0152546102181077\n",
            "Regression and Classification loss are 1.431682825088501 and 0.0028224503621459007\n",
            "Processed image 101/138, Loss: 0.01713927835226059\n",
            "Regression and Classification loss are 6.079229354858398 and 0.007094610016793013\n",
            "Processed image 102/138, Loss: 0.06788690388202667\n",
            "Regression and Classification loss are 0.29576361179351807 and 0.003769168397411704\n",
            "Processed image 103/138, Loss: 0.006726804189383984\n",
            "Regression and Classification loss are 0.5143488645553589 and 0.003758078208193183\n",
            "Processed image 104/138, Loss: 0.008901567198336124\n",
            "Regression and Classification loss are 1.0617319345474243 and 0.001388051314279437\n",
            "Processed image 105/138, Loss: 0.012005371041595936\n",
            "Regression and Classification loss are 5.317229747772217 and 0.0030235545709729195\n",
            "Processed image 106/138, Loss: 0.05619585141539574\n",
            "Regression and Classification loss are 2.3281190395355225 and 0.00124529714230448\n",
            "Processed image 107/138, Loss: 0.024526488035917282\n",
            "Regression and Classification loss are 0.7567510008811951 and 0.002463991753757\n",
            "Processed image 108/138, Loss: 0.01003150176256895\n",
            "Regression and Classification loss are 1.3556617498397827 and 0.002819810528308153\n",
            "Processed image 109/138, Loss: 0.016376428306102753\n",
            "Regression and Classification loss are 0.05570577085018158 and 0.0009273531613871455\n",
            "Processed image 110/138, Loss: 0.0014844108372926712\n",
            "Regression and Classification loss are 0.43217337131500244 and 0.0029568742029368877\n",
            "Processed image 111/138, Loss: 0.007278607692569494\n",
            "Regression and Classification loss are 6.58556604385376 and 0.0008672570111230016\n",
            "Processed image 112/138, Loss: 0.06672291457653046\n",
            "Regression and Classification loss are 1.1981987953186035 and 0.0017786073731258512\n",
            "Processed image 113/138, Loss: 0.01376059465110302\n",
            "Regression and Classification loss are 3.7204506397247314 and 0.0017205867916345596\n",
            "Processed image 114/138, Loss: 0.038925088942050934\n",
            "Regression and Classification loss are 27.510826110839844 and 0.0017365791136398911\n",
            "Processed image 115/138, Loss: 0.2768448293209076\n",
            "Regression and Classification loss are 1.9132709503173828 and 0.0012963321059942245\n",
            "Processed image 116/138, Loss: 0.020429041236639023\n",
            "Regression and Classification loss are 2.8939766883850098 and 0.003319285111501813\n",
            "Processed image 117/138, Loss: 0.032259050756692886\n",
            "Regression and Classification loss are 0.6448838710784912 and 0.004353926982730627\n",
            "Processed image 118/138, Loss: 0.010802765376865864\n",
            "Regression and Classification loss are 1.5279550552368164 and 0.0003834535018540919\n",
            "Processed image 119/138, Loss: 0.01566300354897976\n",
            "Regression and Classification loss are 2.928225040435791 and 0.008064999245107174\n",
            "Processed image 120/138, Loss: 0.03734724968671799\n",
            "Regression and Classification loss are 1.4262187480926514 and 0.003999791573733091\n",
            "Processed image 121/138, Loss: 0.018261978402733803\n",
            "Regression and Classification loss are 0.16756398975849152 and 0.0065552592277526855\n",
            "Processed image 122/138, Loss: 0.008230899460613728\n",
            "Regression and Classification loss are 1.2539759874343872 and 0.0003440916771069169\n",
            "Processed image 123/138, Loss: 0.012883851304650307\n",
            "Regression and Classification loss are 7.825078964233398 and 0.005070570856332779\n",
            "Processed image 124/138, Loss: 0.08332136273384094\n",
            "Regression and Classification loss are 4.977579593658447 and 0.006327801384031773\n",
            "Processed image 125/138, Loss: 0.05610359460115433\n",
            "Regression and Classification loss are 0.25019147992134094 and 0.0026528812013566494\n",
            "Processed image 126/138, Loss: 0.005154795944690704\n",
            "Regression and Classification loss are 3.0474138259887695 and 0.008002452552318573\n",
            "Processed image 127/138, Loss: 0.03847659006714821\n",
            "Regression and Classification loss are 1.0228105783462524 and 0.005310703068971634\n",
            "Processed image 128/138, Loss: 0.015538808889687061\n",
            "Regression and Classification loss are 3.669045925140381 and 0.0012051529483869672\n",
            "Processed image 129/138, Loss: 0.03789561241865158\n",
            "Regression and Classification loss are 12.009077072143555 and 0.004089217633008957\n",
            "Processed image 130/138, Loss: 0.12417998909950256\n",
            "Regression and Classification loss are 0.6813440918922424 and 0.00420727813616395\n",
            "Processed image 131/138, Loss: 0.011020719073712826\n",
            "Regression and Classification loss are 0.7646452784538269 and 0.0031249644234776497\n",
            "Processed image 132/138, Loss: 0.010771417059004307\n",
            "Regression and Classification loss are 4.382691383361816 and 0.004855204839259386\n",
            "Processed image 133/138, Loss: 0.048682115972042084\n",
            "Regression and Classification loss are 1.7434849739074707 and 0.0034947101958096027\n",
            "Processed image 134/138, Loss: 0.02092955820262432\n",
            "Regression and Classification loss are 0.9545018076896667 and 0.001597788417711854\n",
            "Processed image 135/138, Loss: 0.011142806150019169\n",
            "Regression and Classification loss are 0.9399145841598511 and 0.0008526984020136297\n",
            "Processed image 136/138, Loss: 0.010251844301819801\n",
            "Regression and Classification loss are 0.7627448439598083 and 0.002079518511891365\n",
            "Processed image 137/138, Loss: 0.009706966578960419\n",
            "Regression and Classification loss are 1.0724167823791504 and 0.0004983366816304624\n",
            "Processed image 138/138, Loss: 0.011222504079341888\n",
            "Epoch 4/50, Average Loss: 0.048648112525225384\n",
            "Regression and Classification loss are 0.8366796970367432 and 0.006990889087319374\n",
            "Processed image 1/138, Loss: 0.015357686206698418\n",
            "Regression and Classification loss are 0.228575199842453 and 0.0038761813193559647\n",
            "Processed image 2/138, Loss: 0.006161933299154043\n",
            "Regression and Classification loss are 0.1912289410829544 and 0.006679569836705923\n",
            "Processed image 3/138, Loss: 0.008591859601438046\n",
            "Regression and Classification loss are 0.9164172410964966 and 0.006658125203102827\n",
            "Processed image 4/138, Loss: 0.01582229696214199\n",
            "Regression and Classification loss are 0.5362904071807861 and 0.0014261497417464852\n",
            "Processed image 5/138, Loss: 0.006789053790271282\n",
            "Regression and Classification loss are 1.9300200939178467 and 0.005324602127075195\n",
            "Processed image 6/138, Loss: 0.02462480217218399\n",
            "Regression and Classification loss are 0.7295377254486084 and 0.0010282389121130109\n",
            "Processed image 7/138, Loss: 0.008323616348206997\n",
            "Regression and Classification loss are 0.15988217294216156 and 0.004317970015108585\n",
            "Processed image 8/138, Loss: 0.005916791968047619\n",
            "Regression and Classification loss are 506.4180908203125 and 0.007592302281409502\n",
            "Processed image 9/138, Loss: 5.071773052215576\n",
            "Regression and Classification loss are 0.7316142916679382 and 0.004024401307106018\n",
            "Processed image 10/138, Loss: 0.011340543627738953\n",
            "Regression and Classification loss are 0.2472723126411438 and 0.005842319689691067\n",
            "Processed image 11/138, Loss: 0.008315042592585087\n",
            "Regression and Classification loss are 7.3791890144348145 and 0.002880755579099059\n",
            "Processed image 12/138, Loss: 0.07667264342308044\n",
            "Regression and Classification loss are 1.9629473686218262 and 0.0012644210364669561\n",
            "Processed image 13/138, Loss: 0.020893894135951996\n",
            "Regression and Classification loss are 1.3001984357833862 and 0.006752648390829563\n",
            "Processed image 14/138, Loss: 0.01975463330745697\n",
            "Regression and Classification loss are 0.8642683029174805 and 0.0017064767889678478\n",
            "Processed image 15/138, Loss: 0.010349160060286522\n",
            "Regression and Classification loss are 1.0981501340866089 and 0.006202468648552895\n",
            "Processed image 16/138, Loss: 0.017183970659971237\n",
            "Regression and Classification loss are 0.13921649754047394 and 0.00034728102036751807\n",
            "Processed image 17/138, Loss: 0.0017394459573552012\n",
            "Regression and Classification loss are 0.8257620334625244 and 0.0037648677825927734\n",
            "Processed image 18/138, Loss: 0.012022487819194794\n",
            "Regression and Classification loss are 3.896587610244751 and 0.0009258134523406625\n",
            "Processed image 19/138, Loss: 0.03989168629050255\n",
            "Regression and Classification loss are 1.2084808349609375 and 0.0006571818375959992\n",
            "Processed image 20/138, Loss: 0.012741990387439728\n",
            "Regression and Classification loss are 1.337212324142456 and 0.002950467402115464\n",
            "Processed image 21/138, Loss: 0.01632259041070938\n",
            "Regression and Classification loss are 0.6376710534095764 and 0.0024474430829286575\n",
            "Processed image 22/138, Loss: 0.008824152871966362\n",
            "Regression and Classification loss are 0.5506232380867004 and 0.011159457266330719\n",
            "Processed image 23/138, Loss: 0.016665689647197723\n",
            "Regression and Classification loss are 0.7149431705474854 and 0.005189315415918827\n",
            "Processed image 24/138, Loss: 0.012338746339082718\n",
            "Regression and Classification loss are 16.334226608276367 and 0.001699188258498907\n",
            "Processed image 25/138, Loss: 0.1650414615869522\n",
            "Regression and Classification loss are 3.821892738342285 and 0.00188681751023978\n",
            "Processed image 26/138, Loss: 0.04010574519634247\n",
            "Regression and Classification loss are 1.2081153392791748 and 0.004585808143019676\n",
            "Processed image 27/138, Loss: 0.0166669599711895\n",
            "Regression and Classification loss are 0.9583243727684021 and 0.0002452613553032279\n",
            "Processed image 28/138, Loss: 0.009828504174947739\n",
            "Regression and Classification loss are 0.2796928286552429 and 0.00253641651943326\n",
            "Processed image 29/138, Loss: 0.005333344452083111\n",
            "Regression and Classification loss are 0.46040624380111694 and 0.0046180421486496925\n",
            "Processed image 30/138, Loss: 0.009222105145454407\n",
            "Regression and Classification loss are 0.22991131246089935 and 0.003002054989337921\n",
            "Processed image 31/138, Loss: 0.005301168188452721\n",
            "Regression and Classification loss are 1.2644155025482178 and 0.0006703459657728672\n",
            "Processed image 32/138, Loss: 0.013314500451087952\n",
            "Regression and Classification loss are 2.3202500343322754 and 0.002853327663615346\n",
            "Processed image 33/138, Loss: 0.026055827736854553\n",
            "Regression and Classification loss are 8.064648628234863 and 0.0013902083737775683\n",
            "Processed image 34/138, Loss: 0.08203669637441635\n",
            "Regression and Classification loss are 1.0757906436920166 and 0.0021233910229057074\n",
            "Processed image 35/138, Loss: 0.012881297618150711\n",
            "Regression and Classification loss are 0.32073476910591125 and 0.0015222264919430017\n",
            "Processed image 36/138, Loss: 0.004729574080556631\n",
            "Regression and Classification loss are 0.6016709804534912 and 0.002388565568253398\n",
            "Processed image 37/138, Loss: 0.008405275642871857\n",
            "Regression and Classification loss are 2.347905158996582 and 0.001344776595942676\n",
            "Processed image 38/138, Loss: 0.024823827669024467\n",
            "Regression and Classification loss are 0.3424302041530609 and 0.0013811357785016298\n",
            "Processed image 39/138, Loss: 0.004805437754839659\n",
            "Regression and Classification loss are 1.9815260171890259 and 0.0019459245959296823\n",
            "Processed image 40/138, Loss: 0.021761184558272362\n",
            "Regression and Classification loss are 1.8830666542053223 and 0.005513285286724567\n",
            "Processed image 41/138, Loss: 0.024343952536582947\n",
            "Regression and Classification loss are 1.7102644443511963 and 0.005014196969568729\n",
            "Processed image 42/138, Loss: 0.02211683988571167\n",
            "Regression and Classification loss are 0.7425265908241272 and 0.0010488046100363135\n",
            "Processed image 43/138, Loss: 0.008474070578813553\n",
            "Regression and Classification loss are 0.5625791549682617 and 0.001095929415896535\n",
            "Processed image 44/138, Loss: 0.006721721030771732\n",
            "Regression and Classification loss are 12.872344017028809 and 0.0015596994198858738\n",
            "Processed image 45/138, Loss: 0.1302831470966339\n",
            "Regression and Classification loss are 1.1056212186813354 and 0.0041459109634160995\n",
            "Processed image 46/138, Loss: 0.015202122740447521\n",
            "Regression and Classification loss are 0.3122529983520508 and 0.003143114736303687\n",
            "Processed image 47/138, Loss: 0.006265644915401936\n",
            "Regression and Classification loss are 0.2561449110507965 and 0.0035943579860031605\n",
            "Processed image 48/138, Loss: 0.006155807059258223\n",
            "Regression and Classification loss are 1.0931522846221924 and 0.008547358214855194\n",
            "Processed image 49/138, Loss: 0.019478879868984222\n",
            "Regression and Classification loss are 4.998896598815918 and 0.004856948275119066\n",
            "Processed image 50/138, Loss: 0.054845914244651794\n",
            "Regression and Classification loss are 1.3474633693695068 and 0.0022984216921031475\n",
            "Processed image 51/138, Loss: 0.015773054212331772\n",
            "Regression and Classification loss are 1.6565728187561035 and 0.0031167445704340935\n",
            "Processed image 52/138, Loss: 0.019682470709085464\n",
            "Regression and Classification loss are 0.21839550137519836 and 0.006977912038564682\n",
            "Processed image 53/138, Loss: 0.009161867201328278\n",
            "Regression and Classification loss are 0.3527058959007263 and 0.003300944808870554\n",
            "Processed image 54/138, Loss: 0.006828003562986851\n",
            "Regression and Classification loss are 0.39654678106307983 and 0.0010617882944643497\n",
            "Processed image 55/138, Loss: 0.005027255974709988\n",
            "Regression and Classification loss are 1.3669734001159668 and 0.004544803407043219\n",
            "Processed image 56/138, Loss: 0.01821453683078289\n",
            "Regression and Classification loss are 3.85506010055542 and 0.001210917136631906\n",
            "Processed image 57/138, Loss: 0.03976151719689369\n",
            "Regression and Classification loss are 7.1816887855529785 and 0.0039054309017956257\n",
            "Processed image 58/138, Loss: 0.07572231441736221\n",
            "Regression and Classification loss are 1.395533800125122 and 0.004565977957099676\n",
            "Processed image 59/138, Loss: 0.018521316349506378\n",
            "Regression and Classification loss are 0.7791778445243835 and 0.0021932285744696856\n",
            "Processed image 60/138, Loss: 0.009985006414353848\n",
            "Regression and Classification loss are 0.16956087946891785 and 0.0016458443133160472\n",
            "Processed image 61/138, Loss: 0.0033414531499147415\n",
            "Regression and Classification loss are 0.16258051991462708 and 0.0006039423169568181\n",
            "Processed image 62/138, Loss: 0.002229747362434864\n",
            "Regression and Classification loss are 0.6306147575378418 and 0.0022056123707443476\n",
            "Processed image 63/138, Loss: 0.008511759340763092\n",
            "Regression and Classification loss are 0.36844563484191895 and 0.0010597602231428027\n",
            "Processed image 64/138, Loss: 0.004744216334074736\n",
            "Regression and Classification loss are 6.796449184417725 and 0.0025123795494437218\n",
            "Processed image 65/138, Loss: 0.07047686725854874\n",
            "Regression and Classification loss are 2.4215469360351562 and 0.003721918212249875\n",
            "Processed image 66/138, Loss: 0.02793738804757595\n",
            "Regression and Classification loss are 0.3215554654598236 and 0.001975893508642912\n",
            "Processed image 67/138, Loss: 0.0051914481446146965\n",
            "Regression and Classification loss are 0.5674655437469482 and 0.005325588863343\n",
            "Processed image 68/138, Loss: 0.011000243946909904\n",
            "Regression and Classification loss are 0.4828468859195709 and 0.0013834423152729869\n",
            "Processed image 69/138, Loss: 0.006211911328136921\n",
            "Regression and Classification loss are 1.7205250263214111 and 0.0013739358400925994\n",
            "Processed image 70/138, Loss: 0.018579185009002686\n",
            "Regression and Classification loss are 0.3649252653121948 and 0.0016753484960645437\n",
            "Processed image 71/138, Loss: 0.005324601195752621\n",
            "Regression and Classification loss are 0.2898930609226227 and 0.003679680172353983\n",
            "Processed image 72/138, Loss: 0.006578610744327307\n",
            "Regression and Classification loss are 0.8932216167449951 and 0.0007173563353717327\n",
            "Processed image 73/138, Loss: 0.009649572893977165\n",
            "Regression and Classification loss are 1.1883745193481445 and 0.001636112225241959\n",
            "Processed image 74/138, Loss: 0.013519857078790665\n",
            "Regression and Classification loss are 0.5321239829063416 and 0.0008231880492530763\n",
            "Processed image 75/138, Loss: 0.006144427694380283\n",
            "Regression and Classification loss are 2.887169599533081 and 0.001537026953883469\n",
            "Processed image 76/138, Loss: 0.030408721417188644\n",
            "Regression and Classification loss are 7.622906684875488 and 0.0011069943429902196\n",
            "Processed image 77/138, Loss: 0.07733605802059174\n",
            "Regression and Classification loss are 0.28162044286727905 and 0.004550817422568798\n",
            "Processed image 78/138, Loss: 0.00736702186986804\n",
            "Regression and Classification loss are 0.8581681251525879 and 0.000649274152237922\n",
            "Processed image 79/138, Loss: 0.009230955503880978\n",
            "Regression and Classification loss are 1.9374492168426514 and 0.002140676137059927\n",
            "Processed image 80/138, Loss: 0.021515168249607086\n",
            "Regression and Classification loss are 1.9977461099624634 and 0.001439322717487812\n",
            "Processed image 81/138, Loss: 0.021416783332824707\n",
            "Regression and Classification loss are 0.6427215337753296 and 0.004665401764214039\n",
            "Processed image 82/138, Loss: 0.01109261717647314\n",
            "Regression and Classification loss are 0.9851519465446472 and 0.003205052576959133\n",
            "Processed image 83/138, Loss: 0.01305657159537077\n",
            "Regression and Classification loss are 0.5691550374031067 and 0.006904039066284895\n",
            "Processed image 84/138, Loss: 0.012595589272677898\n",
            "Regression and Classification loss are 15.37979507446289 and 0.005400629714131355\n",
            "Processed image 85/138, Loss: 0.1591985821723938\n",
            "Regression and Classification loss are 31.274919509887695 and 0.0037710564211010933\n",
            "Processed image 86/138, Loss: 0.31652024388313293\n",
            "Regression and Classification loss are 0.4287932515144348 and 0.001992256147786975\n",
            "Processed image 87/138, Loss: 0.006280188448727131\n",
            "Regression and Classification loss are 1.8550620079040527 and 0.000470450846478343\n",
            "Processed image 88/138, Loss: 0.01902106963098049\n",
            "Regression and Classification loss are 3.599759101867676 and 0.0033530613873153925\n",
            "Processed image 89/138, Loss: 0.03935065492987633\n",
            "Regression and Classification loss are 0.27920761704444885 and 0.003647421021014452\n",
            "Processed image 90/138, Loss: 0.0064394972287118435\n",
            "Regression and Classification loss are 0.5320300459861755 and 0.0006175186717882752\n",
            "Processed image 91/138, Loss: 0.005937818903476\n",
            "Regression and Classification loss are 0.4964276850223541 and 0.0043573840521276\n",
            "Processed image 92/138, Loss: 0.009321660734713078\n",
            "Regression and Classification loss are 0.957883358001709 and 0.0014033970655873418\n",
            "Processed image 93/138, Loss: 0.010982230305671692\n",
            "Regression and Classification loss are 1.5283918380737305 and 0.004848340526223183\n",
            "Processed image 94/138, Loss: 0.020132258534431458\n",
            "Regression and Classification loss are 0.5249840617179871 and 0.004706663079559803\n",
            "Processed image 95/138, Loss: 0.00995650328695774\n",
            "Regression and Classification loss are 2.93721079826355 and 0.0013934028102084994\n",
            "Processed image 96/138, Loss: 0.030765509232878685\n",
            "Regression and Classification loss are 0.7884029150009155 and 0.0018946088384836912\n",
            "Processed image 97/138, Loss: 0.009778638370335102\n",
            "Regression and Classification loss are 0.3780793845653534 and 0.0013076122850179672\n",
            "Processed image 98/138, Loss: 0.005088406149297953\n",
            "Regression and Classification loss are 245.28981018066406 and 0.0032546846196055412\n",
            "Processed image 99/138, Loss: 2.4561526775360107\n",
            "Regression and Classification loss are 0.8721629977226257 and 0.002337363315746188\n",
            "Processed image 100/138, Loss: 0.011058993637561798\n",
            "Regression and Classification loss are 0.9738258719444275 and 0.001804703613743186\n",
            "Processed image 101/138, Loss: 0.011542961932718754\n",
            "Regression and Classification loss are 4.530813217163086 and 0.004113944713026285\n",
            "Processed image 102/138, Loss: 0.04942207783460617\n",
            "Regression and Classification loss are 0.4789354205131531 and 0.00152766692917794\n",
            "Processed image 103/138, Loss: 0.0063170213252305984\n",
            "Regression and Classification loss are 0.5402013063430786 and 0.005225088447332382\n",
            "Processed image 104/138, Loss: 0.010627101175487041\n",
            "Regression and Classification loss are 0.992612361907959 and 0.0008734107250347733\n",
            "Processed image 105/138, Loss: 0.010799534618854523\n",
            "Regression and Classification loss are 5.056395053863525 and 0.002142188372090459\n",
            "Processed image 106/138, Loss: 0.05270613729953766\n",
            "Regression and Classification loss are 4.121470928192139 and 0.0020830717403441668\n",
            "Processed image 107/138, Loss: 0.04329777881503105\n",
            "Regression and Classification loss are 0.6534081697463989 and 0.0036478708498179913\n",
            "Processed image 108/138, Loss: 0.010181952267885208\n",
            "Regression and Classification loss are 1.4974316358566284 and 0.002520082052797079\n",
            "Processed image 109/138, Loss: 0.01749439723789692\n",
            "Regression and Classification loss are 0.1261359453201294 and 0.0003406049800105393\n",
            "Processed image 110/138, Loss: 0.0016019644681364298\n",
            "Regression and Classification loss are 0.5801619291305542 and 0.002442931989207864\n",
            "Processed image 111/138, Loss: 0.008244550786912441\n",
            "Regression and Classification loss are 6.700833320617676 and 0.003051092615351081\n",
            "Processed image 112/138, Loss: 0.07005942612886429\n",
            "Regression and Classification loss are 0.7744963765144348 and 0.0022130191791802645\n",
            "Processed image 113/138, Loss: 0.009957983158528805\n",
            "Regression and Classification loss are 3.3892815113067627 and 0.000496873224619776\n",
            "Processed image 114/138, Loss: 0.0343896858394146\n",
            "Regression and Classification loss are 27.745986938476562 and 0.0032227085903286934\n",
            "Processed image 115/138, Loss: 0.2806825637817383\n",
            "Regression and Classification loss are 0.7575883865356445 and 0.0009054970578290522\n",
            "Processed image 116/138, Loss: 0.00848138052970171\n",
            "Regression and Classification loss are 4.556661128997803 and 0.0060957553796470165\n",
            "Processed image 117/138, Loss: 0.05166236683726311\n",
            "Regression and Classification loss are 0.6312081813812256 and 0.001970012439414859\n",
            "Processed image 118/138, Loss: 0.00828209426254034\n",
            "Regression and Classification loss are 1.0251669883728027 and 0.009723126888275146\n",
            "Processed image 119/138, Loss: 0.01997479610145092\n",
            "Regression and Classification loss are 4.441052436828613 and 0.005111702252179384\n",
            "Processed image 120/138, Loss: 0.04952222481369972\n",
            "Regression and Classification loss are 0.25030434131622314 and 0.007827140390872955\n",
            "Processed image 121/138, Loss: 0.010330183431506157\n",
            "Regression and Classification loss are 0.3977198600769043 and 0.0033972805831581354\n",
            "Processed image 122/138, Loss: 0.0073744794353842735\n",
            "Regression and Classification loss are 1.5422801971435547 and 0.00207107188180089\n",
            "Processed image 123/138, Loss: 0.017493873834609985\n",
            "Regression and Classification loss are 59.79686737060547 and 0.008329194039106369\n",
            "Processed image 124/138, Loss: 0.6062978506088257\n",
            "Regression and Classification loss are 5.840811729431152 and 0.002096529584378004\n",
            "Processed image 125/138, Loss: 0.060504645109176636\n",
            "Regression and Classification loss are 0.23623661696910858 and 0.002385668456554413\n",
            "Processed image 126/138, Loss: 0.004748034290969372\n",
            "Regression and Classification loss are 4.448078155517578 and 0.0010068232659250498\n",
            "Processed image 127/138, Loss: 0.04548760503530502\n",
            "Regression and Classification loss are 0.5715739130973816 and 0.002173416782170534\n",
            "Processed image 128/138, Loss: 0.00788915529847145\n",
            "Regression and Classification loss are 5.474097728729248 and 0.0021940344013273716\n",
            "Processed image 129/138, Loss: 0.056935012340545654\n",
            "Regression and Classification loss are 12.221843719482422 and 0.004142396152019501\n",
            "Processed image 130/138, Loss: 0.12636083364486694\n",
            "Regression and Classification loss are 0.9321489930152893 and 0.002747714752331376\n",
            "Processed image 131/138, Loss: 0.01206920389086008\n",
            "Regression and Classification loss are 1.3089134693145752 and 0.002306654118001461\n",
            "Processed image 132/138, Loss: 0.015395788475871086\n",
            "Regression and Classification loss are 1.0281813144683838 and 0.0005378765054047108\n",
            "Processed image 133/138, Loss: 0.010819690302014351\n",
            "Regression and Classification loss are 1.5844192504882812 and 0.0038975884672254324\n",
            "Processed image 134/138, Loss: 0.019741781055927277\n",
            "Regression and Classification loss are 0.2732774019241333 and 0.004004145972430706\n",
            "Processed image 135/138, Loss: 0.006736920215189457\n",
            "Regression and Classification loss are 0.24990218877792358 and 0.0003409128694329411\n",
            "Processed image 136/138, Loss: 0.002839934779331088\n",
            "Regression and Classification loss are 0.4442930817604065 and 0.001995273632928729\n",
            "Processed image 137/138, Loss: 0.00643820408731699\n",
            "Regression and Classification loss are 1.0512127876281738 and 0.0004930819268338382\n",
            "Processed image 138/138, Loss: 0.011005209758877754\n",
            "Epoch 5/50, Average Loss: 0.08488737853105599\n",
            "Regression and Classification loss are 0.7300254106521606 and 0.007589067332446575\n",
            "Processed image 1/138, Loss: 0.01488932128995657\n",
            "Regression and Classification loss are 0.18253198266029358 and 0.0009366325102746487\n",
            "Processed image 2/138, Loss: 0.00276195234619081\n",
            "Regression and Classification loss are 0.1269274801015854 and 0.012839404866099358\n",
            "Processed image 3/138, Loss: 0.014108679257333279\n",
            "Regression and Classification loss are 0.5809354782104492 and 0.0040970430709421635\n",
            "Processed image 4/138, Loss: 0.009906398132443428\n",
            "Regression and Classification loss are 0.799825131893158 and 0.0043288287706673145\n",
            "Processed image 5/138, Loss: 0.012327080592513084\n",
            "Regression and Classification loss are 1.259293556213379 and 0.003123019589111209\n",
            "Processed image 6/138, Loss: 0.015715954825282097\n",
            "Regression and Classification loss are 0.5300513505935669 and 0.0034825573675334454\n",
            "Processed image 7/138, Loss: 0.008783070370554924\n",
            "Regression and Classification loss are 0.3690892457962036 and 0.0006424367311410606\n",
            "Processed image 8/138, Loss: 0.0043333289213478565\n",
            "Regression and Classification loss are 63.21949768066406 and 0.006354202516376972\n",
            "Processed image 9/138, Loss: 0.6385491490364075\n",
            "Regression and Classification loss are 0.4802249073982239 and 0.0010772570967674255\n",
            "Processed image 10/138, Loss: 0.005879506003111601\n",
            "Regression and Classification loss are 0.20120826363563538 and 0.006419700104743242\n",
            "Processed image 11/138, Loss: 0.008431782945990562\n",
            "Regression and Classification loss are 7.526808738708496 and 0.004643883556127548\n",
            "Processed image 12/138, Loss: 0.0799119621515274\n",
            "Regression and Classification loss are 0.999176025390625 and 0.0034801869187504053\n",
            "Processed image 13/138, Loss: 0.01347194705158472\n",
            "Regression and Classification loss are 1.261789083480835 and 0.009252868592739105\n",
            "Processed image 14/138, Loss: 0.02187075838446617\n",
            "Regression and Classification loss are 0.6996588706970215 and 0.001930686761625111\n",
            "Processed image 15/138, Loss: 0.00892727542668581\n",
            "Regression and Classification loss are 1.1283650398254395 and 0.001807315507903695\n",
            "Processed image 16/138, Loss: 0.013090965338051319\n",
            "Regression and Classification loss are 0.1051357164978981 and 0.0003218503843527287\n",
            "Processed image 17/138, Loss: 0.00137320754583925\n",
            "Regression and Classification loss are 0.71143639087677 and 0.003649625927209854\n",
            "Processed image 18/138, Loss: 0.010763989761471748\n",
            "Regression and Classification loss are 7.132412910461426 and 0.0013461620546877384\n",
            "Processed image 19/138, Loss: 0.07267028838396072\n",
            "Regression and Classification loss are 1.0717134475708008 and 0.0006358848768286407\n",
            "Processed image 20/138, Loss: 0.011353018693625927\n",
            "Regression and Classification loss are 1.5239850282669067 and 0.0028134535532444715\n",
            "Processed image 21/138, Loss: 0.01805330254137516\n",
            "Regression and Classification loss are 0.6159111261367798 and 0.0025814541149884462\n",
            "Processed image 22/138, Loss: 0.008740564808249474\n",
            "Regression and Classification loss are 1.3597521781921387 and 0.004952166695147753\n",
            "Processed image 23/138, Loss: 0.018549688160419464\n",
            "Regression and Classification loss are 0.665483832359314 and 0.0021543516777455807\n",
            "Processed image 24/138, Loss: 0.00880919024348259\n",
            "Regression and Classification loss are 16.386457443237305 and 0.0015199106419458985\n",
            "Processed image 25/138, Loss: 0.1653844714164734\n",
            "Regression and Classification loss are 3.873119354248047 and 0.00421097269281745\n",
            "Processed image 26/138, Loss: 0.04294216260313988\n",
            "Regression and Classification loss are 1.4627525806427002 and 0.004899280611425638\n",
            "Processed image 27/138, Loss: 0.019526805728673935\n",
            "Regression and Classification loss are 1.1856077909469604 and 0.0008060261025093496\n",
            "Processed image 28/138, Loss: 0.012662103399634361\n",
            "Regression and Classification loss are 0.5003998279571533 and 0.001989830518141389\n",
            "Processed image 29/138, Loss: 0.0069938283413648605\n",
            "Regression and Classification loss are 0.26501113176345825 and 0.0028167327400296926\n",
            "Processed image 30/138, Loss: 0.005466843955218792\n",
            "Regression and Classification loss are 0.1787160485982895 and 0.005404490977525711\n",
            "Processed image 31/138, Loss: 0.007191651500761509\n",
            "Regression and Classification loss are 1.0894248485565186 and 0.0003488869988359511\n",
            "Processed image 32/138, Loss: 0.011243135668337345\n",
            "Regression and Classification loss are 1.5972621440887451 and 0.0023959698155522346\n",
            "Processed image 33/138, Loss: 0.018368590623140335\n",
            "Regression and Classification loss are 1.1883467435836792 and 0.0024650529958307743\n",
            "Processed image 34/138, Loss: 0.014348519966006279\n",
            "Regression and Classification loss are 0.9865579009056091 and 0.004268943332135677\n",
            "Processed image 35/138, Loss: 0.014134522527456284\n",
            "Regression and Classification loss are 0.1589890718460083 and 0.01426911260932684\n",
            "Processed image 36/138, Loss: 0.015859004110097885\n",
            "Regression and Classification loss are 1.0549925565719604 and 0.005926989484578371\n",
            "Processed image 37/138, Loss: 0.016476914286613464\n",
            "Regression and Classification loss are 1.6195614337921143 and 0.0015515212435275316\n",
            "Processed image 38/138, Loss: 0.01774713583290577\n",
            "Regression and Classification loss are 0.4826282858848572 and 0.0062075466848909855\n",
            "Processed image 39/138, Loss: 0.011033829301595688\n",
            "Regression and Classification loss are 0.741637647151947 and 0.004704122897237539\n",
            "Processed image 40/138, Loss: 0.012120499275624752\n",
            "Regression and Classification loss are 1.9223477840423584 and 0.0035108677111566067\n",
            "Processed image 41/138, Loss: 0.022734345868229866\n",
            "Regression and Classification loss are 2.121399402618408 and 0.006203586235642433\n",
            "Processed image 42/138, Loss: 0.027417579665780067\n",
            "Regression and Classification loss are 0.5515884160995483 and 0.0012104905908927321\n",
            "Processed image 43/138, Loss: 0.006726374849677086\n",
            "Regression and Classification loss are 0.47591137886047363 and 0.0007325797923840582\n",
            "Processed image 44/138, Loss: 0.005491693504154682\n",
            "Regression and Classification loss are 12.848690032958984 and 0.0008462693658657372\n",
            "Processed image 45/138, Loss: 0.12933316826820374\n",
            "Regression and Classification loss are 0.8857395648956299 and 0.0033288421109318733\n",
            "Processed image 46/138, Loss: 0.01218623761087656\n",
            "Regression and Classification loss are 0.1452781707048416 and 0.0033019050024449825\n",
            "Processed image 47/138, Loss: 0.00475468672811985\n",
            "Regression and Classification loss are 0.3457028567790985 and 0.0019580554217100143\n",
            "Processed image 48/138, Loss: 0.0054150838404893875\n",
            "Regression and Classification loss are 3.397067070007324 and 0.002072887262329459\n",
            "Processed image 49/138, Loss: 0.03604355454444885\n",
            "Regression and Classification loss are 5.029827117919922 and 0.004366495180875063\n",
            "Processed image 50/138, Loss: 0.05466476455330849\n",
            "Regression and Classification loss are 1.4540215730667114 and 0.002290729433298111\n",
            "Processed image 51/138, Loss: 0.016830943524837494\n",
            "Regression and Classification loss are 1.143639087677002 and 0.004672040697187185\n",
            "Processed image 52/138, Loss: 0.016108430922031403\n",
            "Regression and Classification loss are 1.604461908340454 and 0.0014746704837307334\n",
            "Processed image 53/138, Loss: 0.017519289627671242\n",
            "Regression and Classification loss are 0.6365922689437866 and 0.003248966531828046\n",
            "Processed image 54/138, Loss: 0.00961488950997591\n",
            "Regression and Classification loss are 0.33690640330314636 and 0.0008961696876212955\n",
            "Processed image 55/138, Loss: 0.004265233874320984\n",
            "Regression and Classification loss are 1.2804484367370605 and 0.003038097871467471\n",
            "Processed image 56/138, Loss: 0.015842581167817116\n",
            "Regression and Classification loss are 3.88262677192688 and 0.004837892483919859\n",
            "Processed image 57/138, Loss: 0.04366416111588478\n",
            "Regression and Classification loss are 1.9002548456192017 and 0.002751672174781561\n",
            "Processed image 58/138, Loss: 0.021754220128059387\n",
            "Regression and Classification loss are 1.3676583766937256 and 0.00385751249268651\n",
            "Processed image 59/138, Loss: 0.01753409579396248\n",
            "Regression and Classification loss are 0.24779289960861206 and 0.0055769141763448715\n",
            "Processed image 60/138, Loss: 0.008054843172430992\n",
            "Regression and Classification loss are 0.1838499903678894 and 0.004769908729940653\n",
            "Processed image 61/138, Loss: 0.006608408875763416\n",
            "Regression and Classification loss are 0.7455368041992188 and 0.0006066810456104577\n",
            "Processed image 62/138, Loss: 0.008062048815190792\n",
            "Regression and Classification loss are 0.7449854612350464 and 0.00154830701649189\n",
            "Processed image 63/138, Loss: 0.008998161181807518\n",
            "Regression and Classification loss are 0.3923048675060272 and 0.0003560640034265816\n",
            "Processed image 64/138, Loss: 0.004279112908989191\n",
            "Regression and Classification loss are 9.506205558776855 and 0.002305799163877964\n",
            "Processed image 65/138, Loss: 0.09736785292625427\n",
            "Regression and Classification loss are 0.5844817757606506 and 0.006011564284563065\n",
            "Processed image 66/138, Loss: 0.01185638178139925\n",
            "Regression and Classification loss are 0.41036349534988403 and 0.0037034782581031322\n",
            "Processed image 67/138, Loss: 0.007807113230228424\n",
            "Regression and Classification loss are 0.8531494736671448 and 0.004070058930665255\n",
            "Processed image 68/138, Loss: 0.01260155439376831\n",
            "Regression and Classification loss are 0.3700786828994751 and 0.001791003393009305\n",
            "Processed image 69/138, Loss: 0.005491790361702442\n",
            "Regression and Classification loss are 1.6918344497680664 and 0.001987185562029481\n",
            "Processed image 70/138, Loss: 0.018905529752373695\n",
            "Regression and Classification loss are 0.5082656741142273 and 0.0014230768429115415\n",
            "Processed image 71/138, Loss: 0.006505733355879784\n",
            "Regression and Classification loss are 0.7898246049880981 and 0.005313489586114883\n",
            "Processed image 72/138, Loss: 0.013211735524237156\n",
            "Regression and Classification loss are 0.4129254221916199 and 0.0010044594528153539\n",
            "Processed image 73/138, Loss: 0.005133713595569134\n",
            "Regression and Classification loss are 0.7249858975410461 and 0.0004877233295701444\n",
            "Processed image 74/138, Loss: 0.007737582083791494\n",
            "Regression and Classification loss are 0.8804794549942017 and 0.005745131988078356\n",
            "Processed image 75/138, Loss: 0.014549925923347473\n",
            "Regression and Classification loss are 2.5940287113189697 and 0.0020830449648201466\n",
            "Processed image 76/138, Loss: 0.028023330494761467\n",
            "Regression and Classification loss are 7.056809902191162 and 0.0028340909630060196\n",
            "Processed image 77/138, Loss: 0.07340218871831894\n",
            "Regression and Classification loss are 0.04048306494951248 and 0.0033469409681856632\n",
            "Processed image 78/138, Loss: 0.0037517715245485306\n",
            "Regression and Classification loss are 0.44183680415153503 and 0.0008230329258367419\n",
            "Processed image 79/138, Loss: 0.00524140102788806\n",
            "Regression and Classification loss are 5.867913246154785 and 0.0019619446247816086\n",
            "Processed image 80/138, Loss: 0.06064107269048691\n",
            "Regression and Classification loss are 2.2718517780303955 and 0.0020386925898492336\n",
            "Processed image 81/138, Loss: 0.024757210165262222\n",
            "Regression and Classification loss are 0.6803123950958252 and 0.004151945002377033\n",
            "Processed image 82/138, Loss: 0.010955069214105606\n",
            "Regression and Classification loss are 0.6345639824867249 and 0.0034083789214491844\n",
            "Processed image 83/138, Loss: 0.009754018858075142\n",
            "Regression and Classification loss are 0.8373531103134155 and 0.007495760452002287\n",
            "Processed image 84/138, Loss: 0.015869291499257088\n",
            "Regression and Classification loss are 19.15802001953125 and 0.0048658763989806175\n",
            "Processed image 85/138, Loss: 0.19644606113433838\n",
            "Regression and Classification loss are 77.05045318603516 and 0.0038294049445539713\n",
            "Processed image 86/138, Loss: 0.7743339538574219\n",
            "Regression and Classification loss are 0.34832367300987244 and 0.0014657072024419904\n",
            "Processed image 87/138, Loss: 0.004948943853378296\n",
            "Regression and Classification loss are 2.11543607711792 and 0.0027700401842594147\n",
            "Processed image 88/138, Loss: 0.02392440102994442\n",
            "Regression and Classification loss are 3.8723015785217285 and 0.004850291647017002\n",
            "Processed image 89/138, Loss: 0.04357330501079559\n",
            "Regression and Classification loss are 0.9822801351547241 and 0.005993028171360493\n",
            "Processed image 90/138, Loss: 0.01581582799553871\n",
            "Regression and Classification loss are 0.36770787835121155 and 0.0032036511693149805\n",
            "Processed image 91/138, Loss: 0.006880729924887419\n",
            "Regression and Classification loss are 1.696164608001709 and 0.004648543428629637\n",
            "Processed image 92/138, Loss: 0.021610189229249954\n",
            "Regression and Classification loss are 1.2075846195220947 and 0.0015010181814432144\n",
            "Processed image 93/138, Loss: 0.013576864264905453\n",
            "Regression and Classification loss are 1.5371599197387695 and 0.00392509950324893\n",
            "Processed image 94/138, Loss: 0.01929669827222824\n",
            "Regression and Classification loss are 0.2935469448566437 and 0.005208373069763184\n",
            "Processed image 95/138, Loss: 0.008143842220306396\n",
            "Regression and Classification loss are 4.541018486022949 and 0.002406080486252904\n",
            "Processed image 96/138, Loss: 0.047816261649131775\n",
            "Regression and Classification loss are 2.000433921813965 and 0.0037129297852516174\n",
            "Processed image 97/138, Loss: 0.02371726930141449\n",
            "Regression and Classification loss are 0.1146969273686409 and 0.000985327293165028\n",
            "Processed image 98/138, Loss: 0.0021322965621948242\n",
            "Regression and Classification loss are 5.283464431762695 and 0.0030395130161195993\n",
            "Processed image 99/138, Loss: 0.05587415769696236\n",
            "Regression and Classification loss are 0.09342481940984726 and 0.0015699893701821566\n",
            "Processed image 100/138, Loss: 0.002504237461835146\n",
            "Regression and Classification loss are 0.49061882495880127 and 0.0019579618237912655\n",
            "Processed image 101/138, Loss: 0.006864150054752827\n",
            "Regression and Classification loss are 5.980766773223877 and 0.005251618102192879\n",
            "Processed image 102/138, Loss: 0.06505928188562393\n",
            "Regression and Classification loss are 0.558740496635437 and 0.0014296281151473522\n",
            "Processed image 103/138, Loss: 0.00701703317463398\n",
            "Regression and Classification loss are 0.6029442548751831 and 0.00438808323815465\n",
            "Processed image 104/138, Loss: 0.01041752565652132\n",
            "Regression and Classification loss are 0.5964071154594421 and 0.0012978768208995461\n",
            "Processed image 105/138, Loss: 0.007261947728693485\n",
            "Regression and Classification loss are 5.763153076171875 and 0.003549793502315879\n",
            "Processed image 106/138, Loss: 0.06118132174015045\n",
            "Regression and Classification loss are 3.0218968391418457 and 0.0022349106147885323\n",
            "Processed image 107/138, Loss: 0.032453879714012146\n",
            "Regression and Classification loss are 0.5997689962387085 and 0.0064454469829797745\n",
            "Processed image 108/138, Loss: 0.012443136423826218\n",
            "Regression and Classification loss are 1.8126215934753418 and 0.001870875246822834\n",
            "Processed image 109/138, Loss: 0.019997090101242065\n",
            "Regression and Classification loss are 0.05348897725343704 and 0.002796897664666176\n",
            "Processed image 110/138, Loss: 0.0033317874185740948\n",
            "Regression and Classification loss are 0.3957110643386841 and 0.0024240745697170496\n",
            "Processed image 111/138, Loss: 0.006381184794008732\n",
            "Regression and Classification loss are 6.249100208282471 and 0.00047508208081126213\n",
            "Processed image 112/138, Loss: 0.06296607851982117\n",
            "Regression and Classification loss are 0.7855005860328674 and 0.002496474189683795\n",
            "Processed image 113/138, Loss: 0.010351479984819889\n",
            "Regression and Classification loss are 3.3506217002868652 and 0.001134307705797255\n",
            "Processed image 114/138, Loss: 0.03464052081108093\n",
            "Regression and Classification loss are 26.258136749267578 and 0.0029732566326856613\n",
            "Processed image 115/138, Loss: 0.26555460691452026\n",
            "Regression and Classification loss are 0.906217634677887 and 0.0022408997174352407\n",
            "Processed image 116/138, Loss: 0.011303076520562172\n",
            "Regression and Classification loss are 3.1449055671691895 and 0.0015687926206737757\n",
            "Processed image 117/138, Loss: 0.033017847687006\n",
            "Regression and Classification loss are 0.6038732528686523 and 0.001641544047743082\n",
            "Processed image 118/138, Loss: 0.007680276408791542\n",
            "Regression and Classification loss are 1.5647430419921875 and 0.00045267000677995384\n",
            "Processed image 119/138, Loss: 0.016100099310278893\n",
            "Regression and Classification loss are 0.3180983066558838 and 0.002372037386521697\n",
            "Processed image 120/138, Loss: 0.005553020164370537\n",
            "Regression and Classification loss are 0.7060447931289673 and 0.0020070767495781183\n",
            "Processed image 121/138, Loss: 0.00906752422451973\n",
            "Regression and Classification loss are 0.09823086857795715 and 0.005079554859548807\n",
            "Processed image 122/138, Loss: 0.006061863619834185\n",
            "Regression and Classification loss are 1.2421480417251587 and 0.0003279827069491148\n",
            "Processed image 123/138, Loss: 0.012749463319778442\n",
            "Regression and Classification loss are 39.313411712646484 and 0.005186958238482475\n",
            "Processed image 124/138, Loss: 0.3983210623264313\n",
            "Regression and Classification loss are 5.711104869842529 and 0.002616655081510544\n",
            "Processed image 125/138, Loss: 0.05972770228981972\n",
            "Regression and Classification loss are 0.18130220472812653 and 0.0026513910852372646\n",
            "Processed image 126/138, Loss: 0.004464413039386272\n",
            "Regression and Classification loss are 2.8905255794525146 and 0.002596910111606121\n",
            "Processed image 127/138, Loss: 0.03150216490030289\n",
            "Regression and Classification loss are 1.4344282150268555 and 0.00314210238866508\n",
            "Processed image 128/138, Loss: 0.017486384138464928\n",
            "Regression and Classification loss are 4.27094841003418 and 0.0021053780801594257\n",
            "Processed image 129/138, Loss: 0.04481486231088638\n",
            "Regression and Classification loss are 0.30924248695373535 and 0.004613569937646389\n",
            "Processed image 130/138, Loss: 0.0077059948816895485\n",
            "Regression and Classification loss are 0.9984307885169983 and 0.0034403407480567694\n",
            "Processed image 131/138, Loss: 0.013424648903310299\n",
            "Regression and Classification loss are 1.431830644607544 and 0.0030486241448670626\n",
            "Processed image 132/138, Loss: 0.017366930842399597\n",
            "Regression and Classification loss are 1.4477331638336182 and 0.0008116938406601548\n",
            "Processed image 133/138, Loss: 0.015289025381207466\n",
            "Regression and Classification loss are 1.1401220560073853 and 0.005078438203781843\n",
            "Processed image 134/138, Loss: 0.01647965796291828\n",
            "Regression and Classification loss are 0.7785414457321167 and 0.003800891572609544\n",
            "Processed image 135/138, Loss: 0.011586305685341358\n",
            "Regression and Classification loss are 0.07328314334154129 and 0.0021266047842800617\n",
            "Processed image 136/138, Loss: 0.002859436208382249\n",
            "Regression and Classification loss are 0.5959851145744324 and 0.0019527666736394167\n",
            "Processed image 137/138, Loss: 0.007912618108093739\n",
            "Regression and Classification loss are 1.1539943218231201 and 0.0010791518725454807\n",
            "Processed image 138/138, Loss: 0.012619094923138618\n",
            "Epoch 6/50, Average Loss: 0.03610036315555023\n",
            "Regression and Classification loss are 1.438803791999817 and 0.0034518898464739323\n",
            "Processed image 1/138, Loss: 0.017839927226305008\n",
            "Regression and Classification loss are 0.08953763544559479 and 0.000536553852725774\n",
            "Processed image 2/138, Loss: 0.001431930111721158\n",
            "Regression and Classification loss are 0.28815215826034546 and 0.006645457819104195\n",
            "Processed image 3/138, Loss: 0.009526979178190231\n",
            "Regression and Classification loss are 0.7762534618377686 and 0.005127943120896816\n",
            "Processed image 4/138, Loss: 0.012890477664768696\n",
            "Regression and Classification loss are 0.6865442395210266 and 0.0030199240427464247\n",
            "Processed image 5/138, Loss: 0.009885366074740887\n",
            "Regression and Classification loss are 5.318840503692627 and 0.003350605955347419\n",
            "Processed image 6/138, Loss: 0.056539006531238556\n",
            "Regression and Classification loss are 0.6409267783164978 and 0.0020943062845617533\n",
            "Processed image 7/138, Loss: 0.008503573946654797\n",
            "Regression and Classification loss are 0.11014914512634277 and 0.0035251015797257423\n",
            "Processed image 8/138, Loss: 0.0046265930868685246\n",
            "Regression and Classification loss are 437.13079833984375 and 0.007937419228255749\n",
            "Processed image 9/138, Loss: 4.379245281219482\n",
            "Regression and Classification loss are 0.6249071955680847 and 0.0011942116543650627\n",
            "Processed image 10/138, Loss: 0.007443283684551716\n",
            "Regression and Classification loss are 0.55389404296875 and 0.00434639910236001\n",
            "Processed image 11/138, Loss: 0.009885339066386223\n",
            "Regression and Classification loss are 9.349833488464355 and 0.0014147884212434292\n",
            "Processed image 12/138, Loss: 0.09491312503814697\n",
            "Regression and Classification loss are 1.1984469890594482 and 0.0037458683364093304\n",
            "Processed image 13/138, Loss: 0.01573033817112446\n",
            "Regression and Classification loss are 1.2728915214538574 and 0.012626627460122108\n",
            "Processed image 14/138, Loss: 0.025355542078614235\n",
            "Regression and Classification loss are 0.49901771545410156 and 0.0022209591697901487\n",
            "Processed image 15/138, Loss: 0.007211136631667614\n",
            "Regression and Classification loss are 1.4376370906829834 and 0.0033769370056688786\n",
            "Processed image 16/138, Loss: 0.01775330677628517\n",
            "Regression and Classification loss are 0.23419779539108276 and 0.000868631002958864\n",
            "Processed image 17/138, Loss: 0.003210608847439289\n",
            "Regression and Classification loss are 0.7541700601577759 and 0.004317815415561199\n",
            "Processed image 18/138, Loss: 0.011859515681862831\n",
            "Regression and Classification loss are 3.067495346069336 and 0.0016712346114218235\n",
            "Processed image 19/138, Loss: 0.03234618902206421\n",
            "Regression and Classification loss are 0.855847179889679 and 0.0034835210535675287\n",
            "Processed image 20/138, Loss: 0.012041992507874966\n",
            "Regression and Classification loss are 1.7146034240722656 and 0.003868766827508807\n",
            "Processed image 21/138, Loss: 0.021014800295233727\n",
            "Regression and Classification loss are 0.8252324461936951 and 0.004027015995234251\n",
            "Processed image 22/138, Loss: 0.012279340997338295\n",
            "Regression and Classification loss are 0.57998126745224 and 0.010139492340385914\n",
            "Processed image 23/138, Loss: 0.01593930460512638\n",
            "Regression and Classification loss are 0.7772139310836792 and 0.003222287865355611\n",
            "Processed image 24/138, Loss: 0.010994426906108856\n",
            "Regression and Classification loss are 17.73369026184082 and 0.001874379115179181\n",
            "Processed image 25/138, Loss: 0.17921127378940582\n",
            "Regression and Classification loss are 3.5924508571624756 and 0.0018265523249283433\n",
            "Processed image 26/138, Loss: 0.03775105997920036\n",
            "Regression and Classification loss are 1.3641061782836914 and 0.00406530499458313\n",
            "Processed image 27/138, Loss: 0.017706366255879402\n",
            "Regression and Classification loss are 1.0892689228057861 and 0.0010978017235174775\n",
            "Processed image 28/138, Loss: 0.011990491300821304\n",
            "Regression and Classification loss are 1.5129351615905762 and 0.002742007840424776\n",
            "Processed image 29/138, Loss: 0.01787135936319828\n",
            "Regression and Classification loss are 7.633686065673828 and 0.0023860125802457333\n",
            "Processed image 30/138, Loss: 0.07872287184000015\n",
            "Regression and Classification loss are 0.460035115480423 and 0.003007543971762061\n",
            "Processed image 31/138, Loss: 0.007607894949615002\n",
            "Regression and Classification loss are 1.3203458786010742 and 0.0016319416463375092\n",
            "Processed image 32/138, Loss: 0.014835400506854057\n",
            "Regression and Classification loss are 1.6097943782806396 and 0.0029457714408636093\n",
            "Processed image 33/138, Loss: 0.01904371567070484\n",
            "Regression and Classification loss are 10.334943771362305 and 0.0020420695655047894\n",
            "Processed image 34/138, Loss: 0.1053915023803711\n",
            "Regression and Classification loss are 1.3734216690063477 and 0.0017409047577530146\n",
            "Processed image 35/138, Loss: 0.015475121326744556\n",
            "Regression and Classification loss are 0.5305072069168091 and 0.005756434518843889\n",
            "Processed image 36/138, Loss: 0.01106150634586811\n",
            "Regression and Classification loss are 0.8184685707092285 and 0.005109185818582773\n",
            "Processed image 37/138, Loss: 0.013293871656060219\n",
            "Regression and Classification loss are 2.3087844848632812 and 0.003019071649760008\n",
            "Processed image 38/138, Loss: 0.02610691636800766\n",
            "Regression and Classification loss are 0.13771626353263855 and 0.007533190306276083\n",
            "Processed image 39/138, Loss: 0.008910353295505047\n",
            "Regression and Classification loss are 0.56806480884552 and 0.0014707599766552448\n",
            "Processed image 40/138, Loss: 0.0071514081209897995\n",
            "Regression and Classification loss are 1.021984338760376 and 0.002227665623649955\n",
            "Processed image 41/138, Loss: 0.012447508983314037\n",
            "Regression and Classification loss are 2.612642288208008 and 0.0025133693125098944\n",
            "Processed image 42/138, Loss: 0.028639791533350945\n",
            "Regression and Classification loss are 1.2780158519744873 and 0.003139699576422572\n",
            "Processed image 43/138, Loss: 0.01591985672712326\n",
            "Regression and Classification loss are 0.38139861822128296 and 0.0011256677098572254\n",
            "Processed image 44/138, Loss: 0.0049396539106965065\n",
            "Regression and Classification loss are 12.862982749938965 and 0.0028189474251121283\n",
            "Processed image 45/138, Loss: 0.13144876062870026\n",
            "Regression and Classification loss are 0.8794946670532227 and 0.0036708253901451826\n",
            "Processed image 46/138, Loss: 0.012465772219002247\n",
            "Regression and Classification loss are 0.47507521510124207 and 0.005546127911657095\n",
            "Processed image 47/138, Loss: 0.010296879336237907\n",
            "Regression and Classification loss are 0.2129281461238861 and 0.002851649420335889\n",
            "Processed image 48/138, Loss: 0.004980931058526039\n",
            "Regression and Classification loss are 2.918219566345215 and 0.003935234621167183\n",
            "Processed image 49/138, Loss: 0.03311742842197418\n",
            "Regression and Classification loss are 4.693548202514648 and 0.003965815994888544\n",
            "Processed image 50/138, Loss: 0.050901297479867935\n",
            "Regression and Classification loss are 1.6257550716400146 and 0.0018276525661349297\n",
            "Processed image 51/138, Loss: 0.01808520406484604\n",
            "Regression and Classification loss are 3.13055419921875 and 0.00292432913556695\n",
            "Processed image 52/138, Loss: 0.03422987088561058\n",
            "Regression and Classification loss are 0.38583117723464966 and 0.004532977007329464\n",
            "Processed image 53/138, Loss: 0.008391289040446281\n",
            "Regression and Classification loss are 1.4733532667160034 and 0.004347027745097876\n",
            "Processed image 54/138, Loss: 0.01908056065440178\n",
            "Regression and Classification loss are 0.336490660905838 and 0.004614820703864098\n",
            "Processed image 55/138, Loss: 0.00797972735017538\n",
            "Regression and Classification loss are 1.3348450660705566 and 0.0039516654796898365\n",
            "Processed image 56/138, Loss: 0.017300115898251534\n",
            "Regression and Classification loss are 6.040703296661377 and 0.003496861783787608\n",
            "Processed image 57/138, Loss: 0.06390389055013657\n",
            "Regression and Classification loss are 3.9616990089416504 and 0.003370883408933878\n",
            "Processed image 58/138, Loss: 0.0429878756403923\n",
            "Regression and Classification loss are 1.4399652481079102 and 0.0036857142113149166\n",
            "Processed image 59/138, Loss: 0.018085366114974022\n",
            "Regression and Classification loss are 1.0293101072311401 and 0.005833140574395657\n",
            "Processed image 60/138, Loss: 0.01612624153494835\n",
            "Regression and Classification loss are 0.1602737009525299 and 0.002728352090343833\n",
            "Processed image 61/138, Loss: 0.004331089090555906\n",
            "Regression and Classification loss are 0.3179759383201599 and 0.0015429914928972721\n",
            "Processed image 62/138, Loss: 0.004722750745713711\n",
            "Regression and Classification loss are 1.1579259634017944 and 0.0025186589919030666\n",
            "Processed image 63/138, Loss: 0.014097917824983597\n",
            "Regression and Classification loss are 0.4360353946685791 and 0.0017628383357077837\n",
            "Processed image 64/138, Loss: 0.006123192608356476\n",
            "Regression and Classification loss are 9.996363639831543 and 0.0023627658374607563\n",
            "Processed image 65/138, Loss: 0.102326400578022\n",
            "Regression and Classification loss are 2.532796621322632 and 0.004771329928189516\n",
            "Processed image 66/138, Loss: 0.0300992950797081\n",
            "Regression and Classification loss are 0.8955866098403931 and 0.004846405703574419\n",
            "Processed image 67/138, Loss: 0.013802271336317062\n",
            "Regression and Classification loss are 1.1363219022750854 and 0.005398131906986237\n",
            "Processed image 68/138, Loss: 0.016761351376771927\n",
            "Regression and Classification loss are 0.21939721703529358 and 0.001638583606109023\n",
            "Processed image 69/138, Loss: 0.003832555841654539\n",
            "Regression and Classification loss are 1.534907579421997 and 0.0032630176283419132\n",
            "Processed image 70/138, Loss: 0.01861209236085415\n",
            "Regression and Classification loss are 0.9481589794158936 and 0.0011972462525591254\n",
            "Processed image 71/138, Loss: 0.010678835213184357\n",
            "Regression and Classification loss are 0.35022419691085815 and 0.0028512177523225546\n",
            "Processed image 72/138, Loss: 0.006353459320962429\n",
            "Regression and Classification loss are 0.8770301342010498 and 0.003579280572012067\n",
            "Processed image 73/138, Loss: 0.012349581345915794\n",
            "Regression and Classification loss are 0.8152583837509155 and 0.0019159535877406597\n",
            "Processed image 74/138, Loss: 0.010068537667393684\n",
            "Regression and Classification loss are 1.4204001426696777 and 0.002844137605279684\n",
            "Processed image 75/138, Loss: 0.01704813912510872\n",
            "Regression and Classification loss are 2.421388626098633 and 0.0027200134936720133\n",
            "Processed image 76/138, Loss: 0.026933899149298668\n",
            "Regression and Classification loss are 20.228885650634766 and 0.002110747853294015\n",
            "Processed image 77/138, Loss: 0.20439960062503815\n",
            "Regression and Classification loss are 0.8714456558227539 and 0.0033207228407263756\n",
            "Processed image 78/138, Loss: 0.012035178951919079\n",
            "Regression and Classification loss are 0.48944753408432007 and 0.004245702177286148\n",
            "Processed image 79/138, Loss: 0.009140177629888058\n",
            "Regression and Classification loss are 6.498135089874268 and 0.002262044232338667\n",
            "Processed image 80/138, Loss: 0.06724338978528976\n",
            "Regression and Classification loss are 2.4213175773620605 and 0.0047050705179572105\n",
            "Processed image 81/138, Loss: 0.028918243944644928\n",
            "Regression and Classification loss are 1.1967304944992065 and 0.004893365316092968\n",
            "Processed image 82/138, Loss: 0.01686067134141922\n",
            "Regression and Classification loss are 1.0999661684036255 and 0.0021290506701916456\n",
            "Processed image 83/138, Loss: 0.013128712773323059\n",
            "Regression and Classification loss are 1.1716724634170532 and 0.007445055525749922\n",
            "Processed image 84/138, Loss: 0.019161779433488846\n",
            "Regression and Classification loss are 8.7154541015625 and 0.005779950879514217\n",
            "Processed image 85/138, Loss: 0.0929344892501831\n",
            "Regression and Classification loss are 28.760568618774414 and 0.0027882219292223454\n",
            "Processed image 86/138, Loss: 0.2903938889503479\n",
            "Regression and Classification loss are 0.828913688659668 and 0.0013687469763681293\n",
            "Processed image 87/138, Loss: 0.009657884016633034\n",
            "Regression and Classification loss are 2.822152614593506 and 0.0019647700246423483\n",
            "Processed image 88/138, Loss: 0.03018629550933838\n",
            "Regression and Classification loss are 4.177443504333496 and 0.0054703447967767715\n",
            "Processed image 89/138, Loss: 0.047244779765605927\n",
            "Regression and Classification loss are 0.31993404030799866 and 0.004747490398585796\n",
            "Processed image 90/138, Loss: 0.007946830242872238\n",
            "Regression and Classification loss are 0.857191801071167 and 0.0006346428417600691\n",
            "Processed image 91/138, Loss: 0.009206561371684074\n",
            "Regression and Classification loss are 0.997849702835083 and 0.00397404795512557\n",
            "Processed image 92/138, Loss: 0.013952543959021568\n",
            "Regression and Classification loss are 1.1255855560302734 and 0.0015569840325042605\n",
            "Processed image 93/138, Loss: 0.012812839820981026\n",
            "Regression and Classification loss are 1.4907913208007812 and 0.0023119361139833927\n",
            "Processed image 94/138, Loss: 0.017219848930835724\n",
            "Regression and Classification loss are 0.7101618051528931 and 0.0036917272955179214\n",
            "Processed image 95/138, Loss: 0.010793345049023628\n",
            "Regression and Classification loss are 3.4973833560943604 and 0.002546188421547413\n",
            "Processed image 96/138, Loss: 0.037520021200180054\n",
            "Regression and Classification loss are 0.5110596418380737 and 0.004560049157589674\n",
            "Processed image 97/138, Loss: 0.009670644998550415\n",
            "Regression and Classification loss are 0.15934932231903076 and 0.0014672984834760427\n",
            "Processed image 98/138, Loss: 0.00306079164147377\n",
            "Regression and Classification loss are 4.3368401527404785 and 0.004085811320692301\n",
            "Processed image 99/138, Loss: 0.04745421186089516\n",
            "Regression and Classification loss are 0.15226134657859802 and 0.0037489542737603188\n",
            "Processed image 100/138, Loss: 0.005271567963063717\n",
            "Regression and Classification loss are 0.8546894192695618 and 0.0014461977407336235\n",
            "Processed image 101/138, Loss: 0.009993092156946659\n",
            "Regression and Classification loss are 4.322856903076172 and 0.0044993869960308075\n",
            "Processed image 102/138, Loss: 0.047727953642606735\n",
            "Regression and Classification loss are 0.2709442973136902 and 0.0025815728586167097\n",
            "Processed image 103/138, Loss: 0.005291015841066837\n",
            "Regression and Classification loss are 0.8889852166175842 and 0.004303630441427231\n",
            "Processed image 104/138, Loss: 0.013193482533097267\n",
            "Regression and Classification loss are 1.2181494235992432 and 0.0017212714301422238\n",
            "Processed image 105/138, Loss: 0.013902765698730946\n",
            "Regression and Classification loss are 1.3605000972747803 and 0.002553875558078289\n",
            "Processed image 106/138, Loss: 0.016158875077962875\n",
            "Regression and Classification loss are 0.9870929718017578 and 0.0035295181442052126\n",
            "Processed image 107/138, Loss: 0.013400447554886341\n",
            "Regression and Classification loss are 1.0506715774536133 and 0.0020153014920651913\n",
            "Processed image 108/138, Loss: 0.012522017583251\n",
            "Regression and Classification loss are 1.7988985776901245 and 0.0018943289760500193\n",
            "Processed image 109/138, Loss: 0.01988331414759159\n",
            "Regression and Classification loss are 0.01477318536490202 and 0.004065199289470911\n",
            "Processed image 110/138, Loss: 0.004212931264191866\n",
            "Regression and Classification loss are 21.853986740112305 and 0.0035484647378325462\n",
            "Processed image 111/138, Loss: 0.22208832204341888\n",
            "Regression and Classification loss are 6.284891605377197 and 0.00188767584040761\n",
            "Processed image 112/138, Loss: 0.06473659723997116\n",
            "Regression and Classification loss are 1.0849639177322388 and 0.0030636864248663187\n",
            "Processed image 113/138, Loss: 0.013913325034081936\n",
            "Regression and Classification loss are 4.107166290283203 and 0.002151013584807515\n",
            "Processed image 114/138, Loss: 0.04322267323732376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_run.py\n",
        "cv2_imshow(cv2.imread('results/result.jpg'))"
      ],
      "metadata": {
        "id": "1c1WnDWzGJFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test\n",
        "import torch\n",
        "import cv2\n",
        "from test_run import process_image\n",
        "from pathlib import Path\n",
        "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "weights_Dir = Path('/content/drive/MyDrive/Colab_zip/GroundingDINO/weights')\n",
        "filePaths = [file for file in weights_Dir.iterdir() if file.name.startswith('model_weights')]\n",
        "try: model_weights= str(filePaths[-1])\n",
        "except: model_weights=None\n",
        "IMAGE_PATH = '/content/drive/MyDrive/Colab_zip/GroundingDINO/data/test_images/img.jpg'\n",
        "#IMAGE_PATH = \"/content/Fine_Tune_Grounding_Dino/data/test_images/img_test.jpg\"\n",
        "#TEXT_PROMPT = \"building . pool . carvan .circular stucture\"\n",
        "TEXT_PROMPT = \"carvan\"\n",
        "BOX_TRESHOLD = 0.50\n",
        "TEXT_TRESHOLD = 0.30\n",
        "print(\"choosen weights: \",model_weights)\n",
        "try:\n",
        "  process_image(model_weights=model_weights,\n",
        "        image_path= IMAGE_PATH,\n",
        "        text_prompt=TEXT_PROMPT,\n",
        "        box_threshold=BOX_TRESHOLD,\n",
        "        text_threshold=TEXT_TRESHOLD)\n",
        "  cv2_imshow(cv2.imread('results/result.jpg'))\n",
        "except:print(f\"No Detections found of {TEXT_PROMPT} Category\")"
      ],
      "metadata": {
        "id": "i64zR36Vd2iG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ccb72f-4c7e-4f17-f0bc-09abb4475ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "choosen weights:  /content/drive/MyDrive/Colab_zip/GroundingDINO/weights/model_weights_02_020.pth\n",
            "final text_encoder_type: bert-base-uncased\n",
            "Original boxes size torch.Size([0, 4])\n",
            "The unique detected phrases are set()\n",
            "No Detections found of carvan Category\n"
          ]
        }
      ]
    }
  ]
}